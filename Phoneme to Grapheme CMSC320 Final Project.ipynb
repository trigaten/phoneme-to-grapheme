{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <center>Attention Isn't Quite All You Need: Building a Useful Phoneme to Grapheme (P2G) Recurrent Generative Conversion Model from Scratch with GRUs, Attention, and Subterfuge </center>\n",
    "### <center> Sander Schulhoff, Ryan Brown, Xinyi Liu </center>\n",
    "\n",
    "<center><img src=\"gg.jpg\" alt=\"drawing\" width=\"600\"/></center>\n",
    "\n",
    "<center>\"p2g seq2seq attention model\" by GauGAN</center>\n",
    "\n",
    "### The Importance of Language\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a world where humanity never developed language, would humans still have been able to communicate with the precision required to convey advanced knowledge to other humans? Without language, many of today's inventions and scientific progression\" would never have existed. An evolutionary biologist went as far as to the creation of language as \"the most important evolutionary invention of the last few million years\" (Nowak 2000). Language allows humans to communicate information with a level of precision that no other animal on earth can replicate. According to psychologists and historians, rational thought can happen without language, but communicating and continuing these ideas through generations are the central tendencies that allow humans to cooperate, develop, and thrive across the globe.\n",
    "\n",
    "The Oxford Dictionary describes linguistics as \"the scientific study of language and its structure, including the study of morphology, syntax, phonetics, and semantics\". From that definition, morphology is the study of words, whose smallest character building blocks are graphemes, and phonetics is the pronunciations of those words and graphemes (Oxford English Dictionary 2021). Most humans can process and recognize words based on their oral pronunciation in their local dialect, but oral communication is not the sole form of communication. In this project, we will be focusing solely on the importance and applications of oral communication and phonetics in Artificial Intelligence using Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why Predict Words and Graphemes?\n",
    "Today's speech recognition systems use varying techniques. However, many of the most commonly used speech recognition systems such as Bixby, Siri, Alexa, and Google do not attempt to spell words outside the system's dictionary. For example, a person's name may be easy to pronounce but may have unusual spelling. A food's name may be unique and not listed in dictionaries. To give systems like these a boost in their range of responses, we proposed implementing a new system that attempts to predict graphemes when the word confidence is below a certain threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Our Project\n",
    "Our project aims to predict graphemes from phonemes. After our project completes, the next step is to map audio to phonemes, which would allow a speaker to say any English word that has phonetics and have the model produce a word spelled the way the word sounds. If the model outputs incorrect results, we believe that a robust autocorrect library would often correct the attempted word into the correct word. As a result, we believe that converting phonemes to graphemes is a step towards technology having an enhanced ability to recognize speech and produce text that closely resembles the phonetics of speech, providing enhanced communication between users and computational devices and evolution of communication.\n",
    "\n",
    "### Webscraping and Cleaning Phonetics\n",
    "We chose to web scrape phonetics from two web sources: merriam-webster.com and dictionary.com. However, we attempted\n",
    "multiple pdf sources, which did not yield good results. Our code allows for switching between websites by simply\n",
    "adding a new source in the identified code section. However, after reviewing the data, we discovered that dictionary\n",
    ".com produced better and more consistent results and decided to choose the website as our sole source of data\n",
    "collection. Unfortunately, the structure of the phonetics section of the web pages was not entirely consistent across\n",
    " different words. This inconsistency required us to write code that handled various new edge cases to confirm that\n",
    " our CSV (comma-separated values file) would only contain correct data. We initially used synchronous methods of\n",
    " acquiring data. However, concurrency reduced the program runtime by nearly 75%, as determined by runtime logging. The performance increase allows users to collect data significantly faster, allowing for a larger dataset better finetuning of our model. As a result, we acquired over 78,000 word-phonetic combinations for use with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Necessary Imports\n",
    "We import several packages:\n",
    " \"OS\" to make sure this code works on various operating systems\n",
    "\"re\" to search and match regular expressions\n",
    "\"NumPy\" for their numerical \"random\" function\n",
    "bs4\" for parsing HTML webpages\n",
    "\"codecs\" to have the ability to write unique characters to files using utf-8-sig\n",
    "\"requests\" to request the webpage\n",
    "time for logging the runtime\n",
    "and concurrent.futures for concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4\n",
    "import codecs\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures  # This import is important for concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initialize key variables\n",
    "In order to tailer this file to meet the unique needs of users, we coded several main\n",
    "variablesthat can be interchanged between users. These variables include: website to scrape, the base URL, their list\n",
    " of words to find on the\n",
    "website, a\n",
    "list of all known words with no pages or broken phonetics, the number of words to find, and a list of words that have\n",
    " not yet been attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "codecs.register_error(\"strict\", codecs.ignore_errors)\n",
    "\n",
    "# Basic Background Info\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0\"}\n",
    "merriam = \"https://www.merriam-webster.com/dictionary/\"\n",
    "dictionary_web = \"https://www.dictionary.com/browse/\"\n",
    "base_url = dictionary_web  # URL to get words and phonetics from\n",
    "\n",
    "\n",
    "dict_filename = \"words_beta.txt\"  # `Name of the file containing many words - error\n",
    "err_filename = \"404s.txt\"  # List of all of the known error words to eliminate the future chance of choosing those sites\n",
    "\n",
    "# Get current location based on operating system\n",
    "fileDir = os.path.dirname(os.path.realpath('words_beta.txt'))\n",
    "\n",
    "original_size = 1000  # Change this value to change the dataset size and automatically acquire the amount needed\n",
    "new_size = original_size  # Used to subtract the size of any existing sets from the amount needed.\n",
    "\n",
    "# Do the initial parsing of the dictionary file of words that have not yet been attempted.\n",
    "dict_file = open(dict_filename).read()\n",
    "dict_list = dict_file.split(\"\\n\")\n",
    "curr_words = []\n",
    "dict_len = len(dict_list)\n",
    "\n",
    "# Regex required to remove various characters from webscraped strings.\n",
    "regex = r\"( |\\n([a-z][A-Z])*\\n|\\'|\\[|\\]|ˈ|\\+|\\\"|\\(\" \\\n",
    "        r\"|\\)|ˌ||-|͟|¦|\\||‧|͟|&|1|2|–|—|͟|‧|;|pronunciationat|\\r|\\\\|\\/|for\\d*|\\d)*\"\n",
    "to_replace = r\"^noun |^pronoun |^verb |^adjective |^adverb |^preposition |^conjunction |^interjection \"\n",
    "\n",
    "write_file = \"phonemes-words.csv\"  # The file to write phoneme-words to\n",
    "append_or_write = \"a\"  # w to erase write_file and rewrite, a to append to current csv\n",
    "\n",
    "words_added = 0  # Used to keep track of the total number of words added\n",
    "fixed_set = []  # Set of words added to the phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Initialize intro parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separate the file by lines to retrieve the length\n",
    "if append_or_write == \"a\":\n",
    "    temp_read = codecs.open(write_file, \"r\", \"utf-8-sig\")\n",
    "    new_size -= len(codecs.open(write_file, \"r\", \"utf-8-sig\").read().split(\"\\n\"))\n",
    "    temp_read.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Declare key functions and then run the code to acquire the phonetics efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_Purged:\t\t2\n",
      "Total_Purged:\t\t2\n",
      "15.970731973648071\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# This is the main function to get the urls of size \"size\", returns a list of urls pointing dictionary words+phonetics\n",
    "def get_urls(size):\n",
    "    global dict_list\n",
    "    empty_set = set([None])  # Empty set used to remove empty sets from lists\n",
    "    urls = [None] * size  # Indexing the urls using iterators is around 25% faster than appending\n",
    "\n",
    "    # Keep adding numbers until the target size is reached\n",
    "    # print(len(dict_list))\n",
    "    for i in range(size):\n",
    "        new_num = np.random.randint(0, high=len(dict_list))  # Get random number\n",
    "        word = dict_list[new_num]  # Use random number to retrieve word from dictionary\n",
    "\n",
    "        # Changes the base url to include the new word to get that word from the website\n",
    "        modified_url = base_url + word\n",
    "        urls[i] = modified_url\n",
    "\n",
    "    return_set = set(urls) - empty_set  # Remove empty set and duplicates from list of urls\n",
    "\n",
    "    # Keep getting more urls until the size is reached.\n",
    "    while len(return_set) < size:\n",
    "        print(\"Return Set Length: \" + str(len(return_set)))\n",
    "        return_set.update(get_urls(size - len(return_set)))\n",
    "\n",
    "    return return_set # Returns\n",
    "\n",
    "\n",
    "\n",
    "total_failed = 0  # Uses this variable to track number of items that fail.\n",
    "\n",
    "\"\"\"\n",
    "Takes a html page and word as a parameter to parse and retrieve the word on the page and phonetics.\n",
    "\"\"\"\n",
    "def get_word(curr_page, word):\n",
    "    # A commonly used sequence of lines in this method to add the word to list of unavailable words\n",
    "    def add_err():\n",
    "        # Write the word to the not_found list\n",
    "        not_found = codecs.open(err_filename, \"a\")\n",
    "        not_found.write(word + \"\\n\")\n",
    "        not_found.close()\n",
    "\n",
    "        ## This section is used to determine webscraping progress, but is not necessary\n",
    "        global total_failed, words_added # Access these variables to help calculate number remaining.\n",
    "        total_failed -= 1  # Decrement the total fails if the page is unavailable.\n",
    "        print(\"Failed:\\t\\t\\t\" + str(\"\\t\") + \":\\t\\t\" + word) # Print if the word could not be added\n",
    "\n",
    "    if curr_page.status_code == 404:\n",
    "        add_err()  #\n",
    "        # print(\"Error 404\")\n",
    "        # If the page was not valid, try another number combination\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Retrieve the word and phonetics from the page using bs4\n",
    "        if base_url is merriam:\n",
    "            regex1 = r\"( |\\'|\\[|\\]|ˈ|\\+|\\\"|\\(|\\)|ˌ||-|͟|¦|\\||‧|͟|&|–|—|͟|‧|pronunciationat)*\"\n",
    "            web_result = curr_page.content  # Return the new word and page contents\n",
    "            soup = bs4.BeautifulSoup(web_result, \"html.parser\")\n",
    "            word_soup = soup.find_all('h1', {'class': 'hword'})\n",
    "            phonetics = soup.find_all('span', {'class': 'pr'})\n",
    "\n",
    "        else:\n",
    "            regex1 = r\"(ˈ| |/)\"\n",
    "            web_result = curr_page.content  # Return the new word and page contents\n",
    "            soup = bs4.BeautifulSoup(web_result, \"html.parser\")\n",
    "            word_soup = soup.find_all('h1', {'class': 'css-1sprl0b e1wg9v5m5'})\n",
    "            phonetics = soup.find_all('span', {'class': 'pron-ipa-content css-7iphl0 evh0tcl1'})\n",
    "            # print(str(word_soup) + \",\" + str(phonetics))\n",
    "\n",
    "        # Check if both words are of valid lengths\n",
    "        if len(phonetics) >= 1 and len(word_soup) >= 1:\n",
    "            global new_size, total_failed, words_added  # Total number of words added\n",
    "\n",
    "            actual_word = word_soup[0].text.lower()  # Make sure all text is lowercase\n",
    "\n",
    "            # If the word is already in the set, added it to 404s list to avoid repeating terms\n",
    "            # Some words with suffixes and prefixes used only the base word phonetics, causing repeat terms.\n",
    "            if actual_word in curr_words:\n",
    "                add_err()\n",
    "                return\n",
    "            words_added += 1\n",
    "            phonetics = phonetics[0].text.lower()  # Retrieve phonetics\n",
    "\n",
    "            # Some phonetics have multiple pronunciation variations, we only use one\n",
    "            if \",\" or \";\" in phonetics:\n",
    "                phonetics = phonetics.split(\",\")[0].split(\";\")[0]\n",
    "                # print(\"changed p: \" + phonetics)\n",
    "\n",
    "            # Remove all invalid characters\n",
    "            phonetics = re.sub(to_replace, \"\", phonetics)\n",
    "            fixed_phonetics = re.sub(regex1, \"\", phonetics)\n",
    "            # Combine the words into one line for CSV preparation\n",
    "            csv_formatted = fixed_phonetics + \",\" + actual_word\n",
    "\n",
    "            # Write the line to the file.\n",
    "            text_file = codecs.open(write_file, \"a\", \"utf-8-sig\")\n",
    "            text_file.write(csv_formatted + \"\\n\")\n",
    "            text_file.close()\n",
    "\n",
    "            print(\"Words Left:\\t\\t\" + str(new_size - words_added) + \"\\t\\t\" + csv_formatted)\n",
    "\n",
    "            return csv_formatted  # return the formatted string line\n",
    "\n",
    "        else:\n",
    "            # If the adding part does succeed, then add word to error list\n",
    "            add_err()\n",
    "# This method is used to request and process one url at a time\n",
    "def get_one(url):\n",
    "    curr_page = requests.get(url)\n",
    "    get_word(curr_page, url.replace(base_url, \"\"))\n",
    "    return curr_page.raise_for_status()\n",
    "\n",
    "#   The concurrent method used to retrieve all urls at a maximum rate of 20 requests\n",
    "def get_all(urls):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = [executor.submit(get_one, url) for url in urls]\n",
    "\n",
    "    # Log the results and exceptions after the process is completed\n",
    "    for fut in futures:\n",
    "        if fut.exception() is not None:\n",
    "            print('{}: {}'.format(fut.exception(), 'ERR'))\n",
    "        else:\n",
    "            print('{}: {}'.format(fut.result(), 'OK'))\n",
    "\n",
    "\"\"\"\n",
    "This function removes any invalid characters, words, repeat elements, and fixes the formatting of words,\n",
    "accounts for edge cases, and fixes as much data as it can before writing it to the file or removing the data\n",
    "completely if it cannot be fixed.\n",
    "\"\"\"\n",
    "def remove_invalids():\n",
    "    new_fails = 0 # Number of new elements that are removed\n",
    "    read_file = codecs.open(write_file, \"r\", \"utf-8-sig\") # Retrieve the current phonemes-words list\n",
    "    fix_lines = read_file.read() # Read the file\n",
    "    read_file.close()\n",
    "\n",
    "    init_length = len(fix_lines.split(\"\\n\")) # The original number of of phoneme-word combination.\n",
    "\n",
    "    global regex # the regex function written earlier\n",
    "    # Regex to remove common parts of speech accompanying phonetics to be acquired on dictionary.com\n",
    "    re2 = r\"\\n(noun|pronoun|verb|adjective|adverb|preposition|conjunction|interjection)\"\n",
    "    # print(re.findall(re2, fix_lines)) # Used to debug\n",
    "    fix_lines = re.sub(re2, \"\\n\", fix_lines).replace(\"or,\", \",\") # correct the common edge cases\n",
    "    lines = re.sub(regex, \"\", fix_lines).replace(r\"﻿\", \"\").split(\"\\n\") # remove the formatting, split by line\n",
    "\n",
    "    new_lines = [] # Used to determine what the new lines will be\n",
    "    drop_lines = [] # Used to determine which lines to remove from the set\n",
    "\n",
    "    # Recreate the phoneme-word list object separating by the comma from the CSV file\n",
    "    for line in lines:\n",
    "        split_lines = line.split(\",\")\n",
    "        if len(split_lines) == 2: # Only add the line to new_lines if they are the correct size\n",
    "            new_lines.append(split_lines)\n",
    "\n",
    "        else:\n",
    "            drop_lines.append(line) # Remove the line otherwise\n",
    "\n",
    "    # Remove each element in drop_lines from the original lines list for processing\n",
    "    for line in drop_lines:\n",
    "        lines.remove(line)\n",
    "        # print(\"removed: \" + line)\n",
    "\n",
    "\n",
    "    remove_lines = [] # Lines to remove from the current dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    Remove any elements with phonetics that looks suspicious.\n",
    "    These elements are not within 3 characters of length when compared to the original word.\n",
    "    Remove the term if the line is less than 60% of the original length as well, that would imply a 40% reduction\n",
    "    in length from word to phoneme and is uncommon in the english language.\n",
    "    \"\"\"\n",
    "    for new_line in new_lines:\n",
    "        if len(new_line) == 2 and \\\n",
    "                (len(new_line[0]) < (.6 * len(new_line[1])) or len(new_line[0]) > (len(new_line[1]) + 3)):\n",
    "            remove_lines.append(new_line)\n",
    "\n",
    "        # Lines to remove from the list of words.\n",
    "        elif not len(new_line) == 2:\n",
    "            remove_lines.append(new_line)\n",
    "\n",
    "        else:\n",
    "            # Try to resolve another known edge case\n",
    "            non_abc = re.match(r\"[a-zA-Z]*[^a-zA-Z\\d\\s:][a-zA-Z]*\", new_line[1])\n",
    "            # If the match did not occur, ignore this element.\n",
    "            if non_abc:\n",
    "                print(non_abc.group(0))\n",
    "                remove_lines.append(new_line)\n",
    "\n",
    "    remove_set = set() # Set of items to be removed\n",
    "    remove_lines = remove_lines[:len(remove_lines) - 1] # Removes the empty set.\n",
    "\n",
    "    not_found = codecs.open(err_filename, \"a\") # Add all not found elements to the list of error 404s.\n",
    "\n",
    "    for remove in remove_lines:\n",
    "        #For each line that was successfully added, attempt to add it to the 404s list\n",
    "        try:\n",
    "            remove_set.add(str(remove[0]) + \",\" + str(remove[1]))\n",
    "            not_found.write(str(remove[1]) + \"\\n\")\n",
    "            print(\"Removed: \" + remove[1])\n",
    "            new_fails += 1\n",
    "        except:\n",
    "            try:\n",
    "                print(remove[0])\n",
    "                remove_set.add(str(remove[0]))\n",
    "                not_found.write(str(remove[0]) + \"\\n\")\n",
    "                new_fails += 1\n",
    "            except:\n",
    "                # If this term's formatting is bad, print this did not work and add it to the list of 404s.\n",
    "                print(\"This did not work\")\n",
    "                error = codecs.open(\"weird_words.txt\", \"a\", \"utf-8-sig\")\n",
    "                error.write(str(remove))\n",
    "                error.close()\n",
    "\n",
    "    not_found.close()\n",
    "\n",
    "    # Final set is the set of words remaining to be acquired.\n",
    "    final_set = set(lines) - remove_set - set([\"\"]) - set([\"phonemes,graphemes\\n\"])\n",
    "    purged = init_length - len(final_set) # the difference between start and end lengths is the number purged.\n",
    "\n",
    "    print(\"Total_Purged:\\t\\t\" + str(purged)) #Can be used for debugging or progress verification.\n",
    "\n",
    "    # Empty the phoneme-words file, and write the headers, \"phonemes and graphemes\" to the file first\n",
    "    end_block = codecs.open(write_file, \"w\", \"utf-8-sig\")\n",
    "    end_block.write(\"phonemes,graphemes\\n\")\n",
    "\n",
    "    # Write each of the remaining words, which should have good formatting, in final_set to the phonemes-words list.\n",
    "    for line in final_set:\n",
    "        end_block.write(str(line).lower() + \"\\n\")\n",
    "    end_block.close()\n",
    "\n",
    "    # Reopen the error file, parse the terms in it, create a set.\n",
    "    error_file = codecs.open(err_filename, \"r\", \"utf-8-sig\")\n",
    "    err = set(error_file.read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "    error_file.close()\n",
    "\n",
    "    global dict_list, curr_words\n",
    "    # Get the set of the list of words fro from final set\n",
    "    curr_words = set([word.split(\",\")[1] for word in final_set])\n",
    "    # print(curr_words)\n",
    "    # updated dict fil\n",
    "    new_len = set(dict_list) - curr_words # number of words remaining\n",
    "    # print(str(len(dict_list)) + \",\" + str(len(new_len)) + \",\" + str(len(new_len - err)))\n",
    "    dict_list = list((set(dict_list) - curr_words) - err) # Update the global list of remaining words\n",
    "    return final_set # Return the set of words remaining in the phonemes-words csv\n",
    "\n",
    "times_phon_was_run = 0 # Numebr of times the phon function was run.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The main key function used to request and process size number of word-phonetics.\n",
    "This function will only be called once every time \"size\" has been reached.\n",
    "\"\"\"\n",
    "def phon(size):\n",
    "    # access the global class variables\n",
    "    global new_size\n",
    "    global times_phon_was_run\n",
    "    global words_added, total_failed, dict_list, dict_file\n",
    "\n",
    "    # Set both words added and total failed to 0\n",
    "    words_added = total_failed = 0\n",
    "    group_size = 1000 # How many webpages to scrape before updating 404s and the words_beta word list.\n",
    "    new_size = size\n",
    "\n",
    "    times_phon_was_run += 1 # Used in debugging to track number of times this function is called.\n",
    "    # print(\"Again: \" + str(times_phon_was_run)) # Used in debugging to track number of times this function is called.\n",
    "    rounds = int(size/group_size) # The number of times to acquire group_size elements to reach size\n",
    "\n",
    "    for i in range(rounds):\n",
    "        # print(\"Round: \" + str(i))\n",
    "        urls = get_urls(group_size) # get a list of group_size urls with words from words_beta\n",
    "        get_all(urls) # concurrently acquire size number of urls, downloading up to 20 urls at a time\n",
    "        remove_invalids() # remove any and all invalid elements\n",
    "\n",
    "    urls = get_urls(size - rounds * group_size) # acquire remaining urs, since there will likely be a remainder.\n",
    "    get_all(urls) # get all of the remaining urls after all group sizes have been reached.\n",
    "\n",
    "fixed_set = remove_invalids()  # Removes around 99.9% of current invalid lines before attempting to acquire new words\n",
    "phon(new_size + total_failed)  # Run the main function\n",
    "fixed_set = remove_invalids()  # Remove invalids returns all items currently in the phonetics list\n",
    "\n",
    "\n",
    "# Keep repeating the process of getting phoneme_words until all phonetics are reached.\n",
    "while len(fixed_set) < original_size:\n",
    "    phon(original_size - len(fixed_set))\n",
    "    fixed_set = remove_invalids()\n",
    "\n",
    "\n",
    "# Log the total time the function took to run.\n",
    "total_time = time.time() - start_time\n",
    "print(total_time)\n",
    "\n",
    "# Store the time in the timing document, used to optimize the functions and decrease runtime.\n",
    "time_file = codecs.open(\"conc_timing.txt\", \"a\")\n",
    "time_file.write(str(total_time) + \"\\n\")\n",
    "time_file.close()\n",
    "\n",
    "# Update the words_beta.txt and error by subtracting all words that do not work.\n",
    "a_dict = set(codecs.open(\"words_alpha.txt\", \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "b_write = codecs.open(dict_filename, \"w\", \"utf-8-sig\")\n",
    "err = set(codecs.open(err_filename, \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "err_write = codecs.open(err_filename, \"w\", \"utf-8-sig\")\n",
    "\n",
    "new_dict_set = a_dict - err  # Subtract the set of errors from the beta dictionary\n",
    "\n",
    "# Write each line back to the beta file\n",
    "for word in new_dict_set:\n",
    "    b_write.write(word + \"\\n\")\n",
    "\n",
    "# Write each error back to the error file\n",
    "for errors in err:\n",
    "    err_write.write(errors + \"\\n\")\n",
    "\n",
    "# Close out the file\n",
    "b_write.close()\n",
    "err_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Building the model\n",
    "\n",
    "Now we will discuss building and training the model. First well do a bit of setup, importing libraries and computing vocabularies for phonemes and graphemes. A vocabulary is a set of known tokens corresponding, in our case, to phoneme or grapheme tokens. The grapheme list will just be the English alphabet, but there are many more phonemes in the International Phonetic Alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', 'k', 'y', 'ʊ', 'r', 'ɑ', 'a', 'ɪ', 'z', 'æ', 't', 'ə', 'b', 'n', 'u', 'l', 'm', 'ɛ', 'd', 'e', 'ʃ', 's', 'ʌ', 'g', 'f', 'o', 'θ', 'ɒ', 'i', 'ʒ', 'p', 'ɔ', 'v', 'ː', 'h', 'ŋ', 'w', '̃', 'ɡ', 'j', 'ɜ', 'ð', 'ʰ', 'x', 'c', 'œ', 'ü', 'ɘ', 'ø', 'ĩ']\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import pandas as pd\n",
    "# for logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# compute phoneme/grapheme vocabularies\n",
    "data = pd.read_csv(\"phonemes-words.csv\")\n",
    "phonemes_col = data[\"phonemes\"]\n",
    "graphemes_col = data[\"graphemes\"]\n",
    "# vocabularies contain 0 and 1 as start and end tokens\n",
    "phonemes = ['0', '1']\n",
    "graphemes = ['0', '1']\n",
    "\n",
    "for word in phonemes_col:\n",
    "    for phoneme in word:\n",
    "        if phoneme not in phonemes:\n",
    "            phonemes.append(phoneme)\n",
    "for word in graphemes_col:\n",
    "    for grapheme in word:\n",
    "        if grapheme not in graphemes:\n",
    "            graphemes.append(grapheme)\n",
    "\n",
    "# wow, there are lot of different phonemes!\n",
    "print(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Thats a lot of phonemes. Hopefully the model can learn all of those 🙂.\n",
    "\n",
    "\n",
    "Now lets define a couple of helper functions to encode and decode phoneme/grapheme strings. Computers can't process letters themselves, so when we feed phonemes and graphemes into the model, we will 1-hot encode them. Well also define a Pytorch Dataset object to efficiently iterate through our dataset at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nemes_to_1_hot_seq(string, nemes=\"phonemes\"):\n",
    "    \"\"\"one hot encodes the word according to either\n",
    "    the phoneme or grapheme list\n",
    "        ::returns:: pytorch tensor of one hot encoded characters\n",
    "    \"\"\"\n",
    "    string = '0' + string + '1'\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    seq = []\n",
    "    for i in string:\n",
    "        vec = [0] * len(l)\n",
    "        vec[l.index(i)] = 1\n",
    "        seq.append(vec)\n",
    "\n",
    "    return torch.FloatTensor([seq])\n",
    "\n",
    "def one_hot_to_nemes(arr, nemes=\"phonemes\"):\n",
    "    \"\"\"converts a 1-hot encoding back to characters\"\"\"\n",
    "    seq = []\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    for hot in arr:\n",
    "        x = torch.argmax(hot)\n",
    "        seq.append(l[x])\n",
    "    return seq\n",
    "\n",
    "class P2GDataset(Dataset):\n",
    "    \"\"\"Pytorch dataset object for sampling the dataset\"\"\"\n",
    "    def __init__(self, phoneme_file, device):\n",
    "        df = pd.read_csv(phoneme_file)\n",
    "        self.data = df\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, g = self.data.iloc[idx]\n",
    "        # 1-hot encoding\n",
    "        return nemes_to_1_hot_seq(p, nemes = \"phonemes\").to(self.device), nemes_to_1_hot_seq(g, nemes = \"graphemes\").long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "Before getting into the model itself, lets take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = P2GDataset(\"phonemes-words.csv\", device)\n",
    "# calculate # of words of different lengths\n",
    "dict = {}\n",
    "for index in range(len(dataset.data)):\n",
    "    p, g = dataset.data.iloc[index]\n",
    "    if len(g) in dict:\n",
    "        dict[len(g)] += 1\n",
    "    else:\n",
    "        dict[len(g)] = 1\n",
    "Y = []\n",
    "for ele in dict.keys():\n",
    "    Y.append(dict[ele])\n",
    "X = dict.keys()\n",
    "fig = plt.figure()\n",
    "plt.bar(X, Y, 0.4, color=\"green\")\n",
    "plt.xlabel(\"Length of Word\")\n",
    "plt.ylabel(\"# of Words\")\n",
    "plt.title(\"# of Words of Different Lengths\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the distribution of lengths of words in the dataset. It looks like a normal with a slight leftward skew. The median word length is around 8, which happens to be the sequence length that vanilla seq2seq (e.g. Cho et al) implementations experience signifigant performance degrading. We will use a more complex architecture to hopefully deal with this, and we should expect best performance on words of length 8 since our data is concentrated there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the distribution of letters (graphemes)\n",
    "dict = {}\n",
    "for index in range(len(dataset.data)):\n",
    "    p, g = dataset.data.iloc[index]\n",
    "    lowString = g.lower()\n",
    "    for char in lowString:\n",
    "        if char in dict:\n",
    "            dict[char] += 1\n",
    "        else:\n",
    "            dict[char] = 1\n",
    "Y = []\n",
    "for ele in dict.keys():\n",
    "    Y.append(dict[ele]/len(dataset.data))\n",
    "\n",
    "X = dict.keys()\n",
    "fig = plt.figure()\n",
    "plt.bar(sorted(X), Y, 0.4, color=\"green\")\n",
    "plt.xlabel(\"letter\")\n",
    "plt.ylabel(\"Average Number of Cccurrences in a Word\")\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows the average amount of each letter in words in the dataset. No letter occurs more than once on average, but \"g\" is quite close. We would not expect any letters to occur more than once on average considering that the average word length is 8, but there are 26 grapheme characters. The surplus of \"g\"s is surprising and the unequal distribution of letters may lead to the model overpredicting \"g\"s. \"h\" occurs frequently, but \"f\" does not, so perhaps we will see strange spellings of the \"f\" sound, such as the well known example of \"fish\" being spelled as \"ghoti\" (\"gh\" produces the f sound as in laugh, \"o\" produces the \"ih\" sound as in women, and \"ti\" produces the shh sound as in potion). 🙂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "The model changed significantly over time. We tried the following combinations:\n",
    "\n",
    "Single layer GRU encoder+decoder\n",
    "\n",
    "Double/Triple stacked GRU encoder+decoder\n",
    "\n",
    "Single layer LSTM encoder+decoder\n",
    "\n",
    "We also varied hidden sizes, testing 512 or 1024\n",
    "\n",
    "We settled on the following architecture (hidden size 512):\n",
    "\n",
    "Double bidirectional stacked GRU encoder -> linear layer which accepts the last forward/backward hidden layers and converts them to a vector the size of a single hidden layer -> unstacked unidirectional GRU decoder with Bahdanau attention.\n",
    "\n",
    "## Reasoning\n",
    "Why did we choose these neural networks and combinations, and what were their results? <br>\n",
    "We chose these neural network types because we needed RNN for our sequence inputs, and we needed these RNNs to have cell states to deal with the complex and potentially long input sequences. Accuracy for these models generally sat around 30% on the test set.\n",
    "\n",
    "\n",
    "What was our strategy for increasing accuracy? <br>\n",
    "\n",
    "Deeper models, stacking GRUs, testing LSTMs, introducing attention\n",
    "\n",
    "What else could we do to increase the accuracy? <br>\n",
    "State of the art work on G2P for English (the opposite of our task) uses transformers. This would be the next step for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hidden layer size\n",
    "layer_size = 512\n",
    "# define model architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(len(phonemes), layer_size, 2, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            # takes final forwards and backwards hidden states\n",
    "            nn.Linear(2 * layer_size, layer_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # push vector through encoder\n",
    "        out, hidden = self.encoder(x)\n",
    "        # hidden is [4, 1, layer_size]\n",
    "        # this is because of bidirectionality * double stacked\n",
    "        # we want to grab the \"highest\" layers from the forwards and backwards directions\n",
    "        # dim 1 because hidden[3] and hidden[4] are both [1, layer_size] and we\n",
    "        # want a single batch that has 2*layer_size values\n",
    "        hc = torch.cat((hidden[2], hidden[3]), dim=1)\n",
    "        hidden_for_init = self.fc(hc)\n",
    "\n",
    "        # return context vector\n",
    "        return out, hidden_for_init\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2 from encoder state and 1 from decoder state (since not bidirectional)\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(3*layer_size, layer_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # map energy vectors to single values\n",
    "        self.attention = nn.Linear(layer_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_hiddens, decoder_hidden):\n",
    "        # encoder_hiddens is [1, L, layer_size*2] bc bidirectional\n",
    "        # decoder_hidden is [1, layer_size]\n",
    "        # 1 bc using batch first\n",
    "        num_encoder_hiddens = encoder_hiddens.shape[1]\n",
    "\n",
    "        # make it [1,1,layer_size]\n",
    "        decoder_hidden = torch.unsqueeze(decoder_hidden, 0)\n",
    "\n",
    "        # repeat along second dim to get [4, 1, layer_size]\n",
    "\n",
    "        decoder_hiddens = decoder_hidden.squeeze(0).repeat(1, num_encoder_hiddens, 1)\n",
    "\n",
    "        inputs = torch.cat((encoder_hiddens, decoder_hiddens), 2)\n",
    "\n",
    "        energy = self.energy(inputs)\n",
    "\n",
    "        attention = self.attention(energy)\n",
    "\n",
    "        # want a distribution of attention that sums to 1\n",
    "        return F.softmax(attention, dim=2)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        # decoder GRU takes in previous output word, attention vector, current hidden state\n",
    "        self.decoder = nn.GRU(len(graphemes) + 2*layer_size, layer_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(layer_size*3 + len(graphemes), len(graphemes))\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden_layer, encoder_hiddens):\n",
    "        \"\"\"\n",
    "        Since this function gets called once at a time rather than taking in\n",
    "        a sequence of vectors, we need to pass it the last output. This will be just\n",
    "        a vector of numbers that can be converted to the embedding representing that last output\n",
    "        \"\"\"\n",
    "        # [1,1,layer_size]\n",
    "        attention_vals = self.attention(encoder_hiddens, hidden_layer)\n",
    "        attention_vals = attention_vals.permute(0, 2, 1)\n",
    "\n",
    "        # encoder_hiddens [1,L,layer_size]\n",
    "        # this just multiplies each attention value against the appropriate vector\n",
    "        # and sums the weighted vectors\n",
    "        # will be [1, 1, layer_size]\n",
    "        attended = torch.bmm(attention_vals, encoder_hiddens)\n",
    "        input = torch.cat((attended, input), dim=2)\n",
    "        out, hidden = self.decoder(input, hidden_layer)\n",
    "        # out[1] to get top hidden layer\n",
    "        input_for_fc = torch.cat((input, out), dim = 2)\n",
    "\n",
    "        return self.fc(input_for_fc), hidden\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    \"\"\"The seq2seq model itself\"\"\"\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        # instantiate encoder and decoder with attention\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(Attention())\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, in_seq, out_seq, tf_ratio=0.5):\n",
    "        \"\"\"\n",
    "        :param tf_ratio: is the teacher forcing ratio. It decides how frequently\n",
    "        the model receives its own previously predicted token as opposed to the\n",
    "        known correct token.\n",
    "        \"\"\"\n",
    "        out_len = out_seq.shape[1]\n",
    "        # storing the outputs of the sequence\n",
    "        outputs = torch.zeros(out_len, 1, len(graphemes)).to(self.device)\n",
    "\n",
    "        out_for_at, hidden = self.encoder(in_seq)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "\n",
    "        # perform an embarassing amount of data conversions\n",
    "        input = out_seq[0].unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # for each token in known out sequence (except the first)\n",
    "        for i in range(1, out_len):\n",
    "            out, hidden = self.decoder(input, hidden, out_for_at)\n",
    "            outputs[i] = out\n",
    "\n",
    "            if random.random() > tf_ratio:\n",
    "                # teacher forcing (make next input what the current output token should be)\n",
    "                input = out_seq[i].unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            else:\n",
    "                # use previously output token\n",
    "                x = input.argmax(1)[0]\n",
    "                input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "                input[0][0][x] = 1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def pred_new(self, in_seq):\n",
    "        \"\"\"Method to predict the output sequence for a previously unseen\n",
    "        input sequence. The main difference between this function and forward\n",
    "        is that this function only stops decoding when the model produces and\n",
    "        end token\n",
    "        \"\"\"\n",
    "        encoder_out_for_at, hidden = self.encoder(in_seq)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "        outs = []\n",
    "        while True:\n",
    "            out, hidden = self.decoder(input, hidden, encoder_out_for_at)\n",
    "            outs.append(out)\n",
    "            # in case not hitting end token\n",
    "            if len(outs) > 50:\n",
    "                break\n",
    "            x = input.argmax(1)[0]\n",
    "            input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "            input[0][0][x] = 1\n",
    "            if one_hot_to_nemes(out) == ['1']:\n",
    "                break\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ready to train\n",
    "\n",
    "Now that we have a beautiful architecture, we need to instantiate it as well as a loss function and an optimizer. We use cross entropy loss since the model outputs a \"class\" (one of a number of possible tokens) at each decoding step. Well also use Adam, since more vanilla optimizers (e.g. SGD or SGD+momentum) will tend not to converge on a network this complex.\n",
    "\n",
    "We perform a ~90%-10% train test split and define a function for testing the 0-1 accuracy of the model. 0-1 accuracy counts only the words which the model gets exactly correct.\n",
    "\n",
    "Note that hyperparameters were tuned by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# initialize optimizer/loss func/hyperparams\n",
    "\n",
    "\n",
    "EPOCHS = 15\n",
    "model = seq2seq(device).to(device)\n",
    "# what a beautiful architecture\n",
    "print(\"Model architecture \", model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# train on 70000 words\n",
    "train, test = random_split(dataset, [70000, len(dataset)-70000])\n",
    "dataloader = DataLoader(dataset=train, batch_size=1)\n",
    "print(\"train size \", len(train))\n",
    "print(\"test size \", len(test))\n",
    "\n",
    "def get_0_1_accuracy(test_set, model):\n",
    "    \"\"\"method to compute 1-WER accuracy AKA what % of test_set does model get\n",
    "    exactly correct.\"\"\"\n",
    "    correct = 0\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        true = \"\".join(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))[1:-1]\n",
    "        print(true)\n",
    "        pred = \"\".join(one_hot_to_nemes(prediction, \"graphemes\"))[0:-1]\n",
    "        print(pred)\n",
    "\n",
    "        if true == pred:\n",
    "            correct+= 1\n",
    "    if correct == 0:\n",
    "        return correct\n",
    "    return correct/len(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"# of model parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wow 10 million params! This model has more trainable parameters than tonnes of potatoes France produced in 2016! (absolutely no semantic relation). This might take a while to train, so make sure to use a NVIDIA GeForce RTX 3090 Ti 🙂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Our training loop is quite simple. We use a batch size of 1, so as not to deal with padding/packing. We record a couple metrics like loss and current accuracy on the test set as the model progresses. This part will likely take a while to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"tensorboard_data\")\n",
    "# get a mini testing batch to check model accuracy on the test set\n",
    "# throughout training\n",
    "# NOTE: this is not a validation set\n",
    "_, mini_test = random_split(test, [20, len(test)-20])\n",
    "\n",
    "# begin training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        # batch size of 1\n",
    "        in_seq = in_seq.squeeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "        # perform inference\n",
    "        model_output = model(in_seq, out_seq)\n",
    "        # dont compute loss using first token of in/out sequence\n",
    "        model_output = model_output[1:]\n",
    "        model_output = model_output.squeeze(1)\n",
    "        out_seq = out_seq.squeeze(0)[1:]\n",
    "        # compute loss\n",
    "        loss = loss_func(model_output, out_seq.argmax(1).to(device))\n",
    "        # record loss\n",
    "        tot_loss+=loss.detach().item()\n",
    "        # accumulate gradients\n",
    "        loss.backward()\n",
    "        # step and clear grads\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    tot_loss/=len(train)\n",
    "    # record current accuracy on test set and average loss\n",
    "    writer.add_scalar(\"tensorboard_data/acc\", get_0_1_accuracy(mini_test, model), epoch)\n",
    "    writer.add_scalar(\"tensorboard_data/loss\", tot_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# turn dropout off\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Test accuracy: \" + str(get_0_1_accuracy(test, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well that accuracy is... okay. It might be better than the average human (when faced with 10s of thousands of words), but thats still a lot of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![alt text](secret_ingredient.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred_lists(test_set, model):\n",
    "    \"\"\"Returns a list of correct outputs and a corresponding list of model predictions\"\"\"\n",
    "    trues = []\n",
    "    preds = []\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        true = \"\".join(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))[1:-1]\n",
    "        trues.append(true)\n",
    "        pred = \"\".join(one_hot_to_nemes(prediction, \"graphemes\"))[0:-1]\n",
    "        preds.append(pred)\n",
    "\n",
    "    return trues, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "dict_filename = \"words_beta.txt\"  # `Name of the file containing many words - error\n",
    "err_filename = \"404s.txt\"  # List of all of the known error words\n",
    "\n",
    "dict_file = open(dict_filename).read()\n",
    "dict_list = dict_file.split(\"\\n\")\n",
    "\n",
    "a_dict = set(codecs.open(\"words_alpha.txt\", \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "# b_write = codecs.open(dict_filename, \"w\", \"utf-8-sig\")\n",
    "err = set(codecs.open(err_filename, \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "\n",
    "new_dict_set = list(a_dict - err)  # Subtract the set of errors from the beta dictionary\n",
    "\n",
    "spellcheck = SpellChecker().correction\n",
    "trues, preds = get_true_pred_lists(test, model)\n",
    "\n",
    "def spellcheck_all(str_list, correct_list):\n",
    "    new_dict = [None] * len(str_list)\n",
    "    total_equal = 0\n",
    "    str_list = list(str_list)\n",
    "    print(str_list)\n",
    "\n",
    "    for i in range(len(str_list)):\n",
    "        if not str_list[i] in a_dict:\n",
    "            new_dict[i] = (spellcheck(\"\".join(str_list[i])))\n",
    "            print(\"new_word: \" + new_dict[i])\n",
    "        else:\n",
    "            new_dict[i] = str_list[i]\n",
    "\n",
    "        if new_dict[i] == str_list[i]:\n",
    "            total_equal += 1\n",
    "\n",
    "    print(\"original list: \" + str(new_dict))\n",
    "    difference = set(new_dict) - set(correct_list)\n",
    "    return (difference, total_equal/len(str_list))\n",
    "\n",
    "print(str(spellcheck_all(preds, trues)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Resources\n",
    "If the reader would like more resources related to this topic:\n",
    "\n",
    "For learning the basics of RNNs, LSTMs, GRUs, attention (including Bahdanau), and seq2seq architectures, these resources are good:\n",
    "\n",
    "https://www.deeplearningbook.org/contents/rnn.html\n",
    "\n",
    "https://d2l.ai/chapter_recurrent-modern/seq2seq.html\n",
    "\n",
    "https://d2l.ai/chapter_attention-mechanisms/bahdanau-attention.html\n",
    "\n",
    "For more comprehensive tutorials that walk through the full deep learning process (including varied seq2seq architectures such as transformer), this is a good resource:\n",
    "\n",
    "https://github.com/bentrevett/pytorch-seq2seq\n",
    "\n",
    "These papers discuss grapheme->phoneme conversion with deep learning. This is an easier problem, but still requires complex models for high success rates:\n",
    "\n",
    "https://arxiv.org/abs/2004.06338\n",
    "\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43264.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
