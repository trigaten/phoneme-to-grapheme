{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <center>Attention Isn't Quite All You Need: Building a SOTA Phoneme to Grapheme (P2G) Recurrent Generative Conversion Model from Scratch with GRUs, Attention, and a Little Bit of Subterfuge </center>\n",
    "### <center> Sander Schulhoff, Ryan Brown, Xinyi Liu </center>\n",
    "\n",
    "<center><img src=\"gg.jpg\" alt=\"drawing\" width=\"600\"/></center>\n",
    "\n",
    "<center>\"p2g seq2seq attention model\" by GauGAN</center>\n",
    "\n",
    "### The Importance of Language\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a world where humanity never developed language, would humans still have been able to communicate with the precision required to convey advanced knowledge to other humans? Without language, many of today's inventions and scientific progressions would never have existed. An evolutionary biologist went as far as saying that the creation of language is \"the most important evolutionary invention of the last few million years\" (Nowak 2000). Language allows humans to communicate information with a level of precision that no other animal on earth can replicate. According to psychologists and historians, rational thought can happen without language, but communicating and passing these ideas down through generations are the central tendencies that allow humans to cooperate, develop, and thrive across the globe.\n",
    "\n",
    "The Oxford Dictionary describes linguistics as \"the scientific study of language and its structure, including the\n",
    "study of morphology, syntax, phonetics, and semantics\". From that definition, morphology is the study of words, whose\n",
    " smallest character building blocks are graphemes, and phonetics is the pronunciations of those words and graphemes\n",
    " (Oxford English Dictionary 2021). Most humans can process and recognize words based on their oral pronunciation in\n",
    " their local dialect, but oral communication is not the sole form of communication. In this project, we will be\n",
    " focusing on the importance and applications of oral communication. To accomplish this, we apply data science to\n",
    " create a neural network that converts a word's phonetics to its grapheme (or english character) spelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why Predict Words and Graphemes?\n",
    "Today's speech recognition systems use varied techniques. However, many of the most commonly used speech recognition\n",
    "systems such as Bixby, Siri, Alexa, and Google do not attempt to spell words outside the system's dictionary. For\n",
    "example, a person's name may be easy to pronounce, but may have unusual spelling. A food's name may be unique and not\n",
    " listed in dictionaries. To give speech interpretation systems, like Alexa and Siri, a boost in their range of\n",
    " responses, we proposed implementing a new system that attempts to predict graphemes from phoneme spelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Our Project\n",
    "Our project aims to predict graphemes from phonemes. After the completion of our project, the next step would be to\n",
    "map audio to phonemes, which would allow a speaker to say any English word and have the model produce the\n",
    "corresponding spelling. If the model outputs incorrect results, we hypothesized that a robust autocorrect library would\n",
    "often correct the attempted word into the correct word. As a result, we expect that converting phonemes to graphemes\n",
    "to be a step towards technology having an enhanced ability to recognize speech and produce text that closely resembles\n",
    "the phonetics of speech, providing enhanced communication between users and computational devices and aiding in the evolution of communication.\n",
    "\n",
    "### Webscraping and Cleaning Phonetics\n",
    "We chose to web scrape phonetic spellings from two web sources: merriam-webster.com and dictionary.com. We also attempted to use\n",
    "multiple pdf sources, which did not yield good results. Our code allows for switching between websites by simply\n",
    "adding a new source in the identified code section. However, after reviewing the data, we discovered that dictionary\n",
    ".com produced better and more consistent results, so we decided to choose that website as our sole source of data\n",
    "collection. Unfortunately, the structure of the phonetics section of the web pages was not entirely consistent across\n",
    " different words. This inconsistency required us to write code that handled various new edge cases in order to ensure that\n",
    " our CSV (comma-separated values file) would only contain correct data. We initially used synchronous methods of\n",
    " acquiring data. However, concurrency reduced the program runtime by nearly 75%, as determined by runtime logging. The performance increase allowed us to collect data significantly faster, allowing for a larger dataset and better finetuning of our model. As a result, we acquired over 78,000 phoneme-grapheme combinations for use with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Necessary Imports\n",
    "For scraping, we import several packages:\n",
    "\n",
    "\"OS\" to make sure this code works on various operating systems <br>\n",
    "\"re\" to search and match regular expressions <br>\n",
    "\"NumPy\" for their numerical \"random\" function <br>\n",
    "\"bs4\" for parsing HTML webpages <br>\n",
    "\"codecs\" to have the ability to write unique characters to files using utf-8-sig <br>\n",
    "\"requests\" to request the webpage <br>\n",
    "\"time\" for logging the runtime <br>\n",
    "\"concurrent.futures\" for concurrency <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4\n",
    "import codecs\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures  # This import is important for concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initialize key variables\n",
    "In order to tailer this file to meet the unique needs of users, we coded several main\n",
    "variablesthat can be interchanged between users. These variables include: website to scrape, the base URL, their list\n",
    " of words to find on the\n",
    "website, a\n",
    "list of all known words with no pages or broken phonetics, the number of words to find, and a list of words that have\n",
    " not yet been attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "codecs.register_error(\"strict\", codecs.ignore_errors)\n",
    "\n",
    "# Basic Background Info\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0\"}\n",
    "merriam = \"https://www.merriam-webster.com/dictionary/\"\n",
    "dictionary_web = \"https://www.dictionary.com/browse/\"\n",
    "base_url = dictionary_web  # URL to get words and phonetics from\n",
    "\n",
    "dict_filename = \"words_beta.txt\"  # `Name of the file containing many words - error\n",
    "err_filename = \"404s.txt\"  # List of all of the known error words to eliminate the future chance of choosing those sites\n",
    "\n",
    "# Get current location based on operating system\n",
    "fileDir = os.path.dirname(os.path.realpath('words_beta.txt'))\n",
    "\n",
    "original_size = 1000  # Change this value to change the dataset size and automatically acquire the amount needed\n",
    "new_size = original_size  # Used to subtract the size of any existing sets from the amount needed.\n",
    "\n",
    "# Do the initial parsing of the dictionary file of words that have not yet been attempted.\n",
    "dict_file = open(dict_filename).read()\n",
    "dict_list = dict_file.split(\"\\n\")\n",
    "curr_words = []\n",
    "dict_len = len(dict_list)\n",
    "\n",
    "# Regex required to remove various characters from webscraped strings, cannot use \\w since there are non letter chars.\n",
    "regex = r\"( |\\n([a-z][A-Z])*\\n|\\'|\\[|\\]|ˈ|\\+|\\\"|\\(\"\n",
    "        r\"|\\)|ˌ||-|͟|¦|\\||‧|͟|&|–|—|͟|‧|;|pronunciationat|\\r|\\\\|\\/|for\\d*|\\d)*\"\n",
    "to_replace = r\"^noun |^pronoun |^verb |^adjective |^adverb |^preposition |^conjunction |^interjection \"\n",
    "\n",
    "write_file = \"phonemes-words.csv\"  # The file to write phoneme-words to\n",
    "append_or_write = \"a\"  # w to erase write_file and rewrite, a to append to current csv\n",
    "\n",
    "words_added = 0  # Used to keep track of the total number of words added\n",
    "fixed_set = []  # Set of words added to the phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Initialize intro parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separate the file by lines to retrieve the length\n",
    "if append_or_write == \"a\":\n",
    "    temp_read = codecs.open(write_file, \"r\", \"utf-8-sig\")\n",
    "    new_size -= len(codecs.open(write_file, \"r\", \"utf-8-sig\").read().split(\"\\n\"))\n",
    "    temp_read.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Declare key functions and then run the code to acquire the phonetics efficiently\n",
    "This section consists of several key functions, get_urls(), get_word(), get_one(), and get_all(). These functions are\n",
    " the\n",
    "functions that allow users to retrieve information from various dictionary sites. get_urls() retrieves (size) random\n",
    "words from the word list and converts them into the appropriate url. get_all() requests URLs concurrently by\n",
    "using multithreading to call get_one(). get_one() requests one webpage from urls. The HTML result is then processed\n",
    "by get_word(), which retrieves the correct word and its respective phonetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def get_urls(size):\n",
    "    \"\"\"\n",
    "    This is the main function to get the urls of size \"size\", returns a list of urls pointing dictionary words+phonetics\n",
    "\n",
    "    :param size: the number of unique urls to create using the words_beta words list\n",
    "    :type size: int\n",
    "    :return: set of unique URLs with names\n",
    "    \"\"\"\n",
    "    global dict_list\n",
    "    empty_set = set([None])  # Empty set used to remove empty sets from lists\n",
    "    urls = [None] * size  # Indexing the urls using iterators is around 25% faster than appending\n",
    "\n",
    "    # Keep adding numbers until the target size is reached\n",
    "    # print(len(dict_list))\n",
    "    for i in range(size):\n",
    "        new_num = np.random.randint(0, high=len(dict_list))  # Get random number\n",
    "        word = dict_list[new_num]  # Use random number to retrieve word from dictionary\n",
    "\n",
    "        # Changes the base url to include the new word to get that word from the website\n",
    "        modified_url = base_url + word\n",
    "        urls[i] = modified_url\n",
    "\n",
    "    return_set = set(urls) - empty_set  # Remove empty set and duplicates from list of urls\n",
    "\n",
    "    # Keep getting more urls until the size is reached.\n",
    "    while len(return_set) < size:\n",
    "        print(\"Return Set Length: \" + str(len(return_set)))\n",
    "        return_set.update(get_urls(size - len(return_set)))\n",
    "\n",
    "    return return_set  # Returns\n",
    "\n",
    "\n",
    "total_failed = 0  # Uses this variable to track number of items that fail.\n",
    "\n",
    "\n",
    "def get_word(curr_page, word):\n",
    "    \"\"\"\n",
    "    Takes a html page and word as a parameter to parse and retrieve the word on the page and phonetics.\n",
    "\n",
    "    :param curr_page: Stored HTML page to parse and scrape\n",
    "    :param word: The word to scrape from the page\n",
    "    :type curr_page: HTML\n",
    "    :type word: str\n",
    "    :rtype: str\n",
    "\n",
    "    :return: string formatted as \"phoneme,word\" for storage as a CSV file\n",
    "    \"\"\"\n",
    "\n",
    "    def add_err():\n",
    "        \"\"\"\n",
    "        # A commonly used sequence of lines in this method to add the word to list of unavailable words\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Write the word to the not_found list\n",
    "        not_found = codecs.open(err_filename, \"a\")\n",
    "        not_found.write(word + \"\\n\")\n",
    "        not_found.close()\n",
    "\n",
    "        ## This section is used to determine webscraping progress, but is not necessary\n",
    "        global total_failed, words_added  # Access these variables to help calculate number remaining.\n",
    "        total_failed -= 1  # Decrement the total fails if the page is unavailable.\n",
    "        print(\"Failed:\\t\\t\\t\" + str(\"\\t\") + \":\\t\\t\" + word)  # Print if the word could not be added\n",
    "\n",
    "    if curr_page.status_code == 404:\n",
    "        add_err()\n",
    "        # If the page was not valid, try another number combination\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Retrieve the word and phonetics from the page using bs4\n",
    "        if base_url is merriam:\n",
    "            regex1 = r\"( |\\'|\\[|\\]|ˈ|\\+|\\\"|\\(|\\)|ˌ||-|͟|¦|\\||‧|͟|&|–|—|͟|‧|pronunciationat)*\"\n",
    "            web_result = curr_page.content  # Return the new word and page contents\n",
    "            soup = bs4.BeautifulSoup(web_result, \"html.parser\")\n",
    "            word_soup = soup.find_all('h1', {'class': 'hword'})\n",
    "            phonetics = soup.find_all('span', {'class': 'pr'})\n",
    "\n",
    "        else:\n",
    "            regex1 = r\"(ˈ| |/)\"\n",
    "            web_result = curr_page.content  # Return the new word and page contents\n",
    "            soup = bs4.BeautifulSoup(web_result, \"html.parser\")\n",
    "            word_soup = soup.find_all('h1', {'class': 'css-1sprl0b e1wg9v5m5'})\n",
    "            phonetics = soup.find_all('span', {'class': 'pron-ipa-content css-7iphl0 evh0tcl1'})\n",
    "            # print(str(word_soup) + \",\" + str(phonetics))\n",
    "\n",
    "        # Check if both words are of valid lengths\n",
    "        if len(phonetics) >= 1 and len(word_soup) >= 1:\n",
    "            global new_size, total_failed, words_added  # Total number of words added\n",
    "\n",
    "            actual_word = word_soup[0].text.lower()  # Make sure all text is lowercase\n",
    "\n",
    "            # If the word is already in the set, added it to 404s list to avoid repeating terms\n",
    "            # Some words with suffixes and prefixes used only the base word phonetics, causing repeat terms.\n",
    "            if actual_word in curr_words:\n",
    "                add_err()\n",
    "                return\n",
    "            words_added += 1\n",
    "            phonetics = phonetics[0].text.lower()  # Retrieve phonetics\n",
    "\n",
    "            # Some phonetics have multiple pronunciation variations, we only use one\n",
    "            if \",\" or \";\" in phonetics:\n",
    "                phonetics = phonetics.split(\",\")[0].split(\";\")[0]\n",
    "                # print(\"changed p: \" + phonetics)\n",
    "\n",
    "            # Remove all invalid characters\n",
    "            phonetics = re.sub(to_replace, \"\", phonetics)\n",
    "            fixed_phonetics = re.sub(regex1, \"\", phonetics)\n",
    "            # Combine the words into one line for CSV preparation\n",
    "            csv_formatted = fixed_phonetics + \",\" + actual_word\n",
    "\n",
    "            # Write the line to the file.\n",
    "            text_file = codecs.open(write_file, \"a\", \"utf-8-sig\")\n",
    "            text_file.write(csv_formatted + \"\\n\")\n",
    "            text_file.close()\n",
    "\n",
    "            print(\"Words Left:\\t\\t\" + str(new_size - words_added) + \"\\t\\t\" + csv_formatted)\n",
    "\n",
    "            return csv_formatted  # return the formatted string line\n",
    "\n",
    "        else:\n",
    "            # If the adding part does succeed, then add word to error list\n",
    "            add_err()\n",
    "\n",
    "\n",
    "def get_one(url):\n",
    "    \"\"\"\n",
    "    Request and process one url at a time\n",
    "\n",
    "    :param url: the url to request\n",
    "    :rtype: HTTP error handler\n",
    "    \"\"\"\n",
    "    curr_page = requests.get(url)\n",
    "    get_word(curr_page, url.replace(base_url, \"\"))\n",
    "    return curr_page.raise_for_status()\n",
    "\n",
    "\n",
    "def get_all(urls):\n",
    "    \"\"\"\n",
    "    Concurrent method used to retrieve all urls at a maximum rate of 20 requests\n",
    "\n",
    "    :param urls: the list of urls to request\n",
    "    :type urls: list\n",
    "    \"\"\"\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = [executor.submit(get_one, url) for url in urls]\n",
    "\n",
    "    # Log the results and exceptions after the process is completed\n",
    "    for fut in futures:\n",
    "        if fut.exception() is not None:\n",
    "            print('{}: {}'.format(fut.exception(), 'ERR'))\n",
    "        else:\n",
    "            print('{}: {}'.format(fut.result(), 'OK'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Clean the Data\n",
    "This is one of the most important functions in the data gathering phase. Without clean data, the model would not be\n",
    "able to give accurate predictions. Remove invalids is the result of many iterations and reviews of thousands of words\n",
    " to find edge cases and account for them in the code. We remove various symbols, phrases, and filter out by\n",
    " phoneme-word letter difference to create a hard margin that will almost always produce accurate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_invalids():\n",
    "    \"\"\"\n",
    "    This function removes any invalid characters, words, repeat elements, and fixes the formatting of words,\n",
    "    accounts for edge cases, and fixes as much data as it can before writing it to the file or removing the data\n",
    "    completely if it cannot be fixed.\n",
    "\n",
    "    :rtype: set\n",
    "    :return: set of remaining words after all invalid words are removed\n",
    "    \"\"\"\n",
    "    new_fails = 0  # Number of new elements that are removed\n",
    "    read_file = codecs.open(write_file, \"r\", \"utf-8-sig\")  # Retrieve the current phonemes-words list\n",
    "    fix_lines = read_file.read()  # Read the file\n",
    "    read_file.close()\n",
    "\n",
    "    init_length = len(fix_lines.split(\"\\n\"))  # The original number of of phoneme-word combination.\n",
    "\n",
    "    global regex  # the regex function written earlier\n",
    "    # Regex to remove common parts of speech accompanying phonetics to be acquired on dictionary.com\n",
    "    re2 = r\"\\n(noun|pronoun|verb|adjective|adverb|preposition|conjunction|interjection)\"\n",
    "    # print(re.findall(re2, fix_lines)) # Can be used to debug/discover all lines that match re2\n",
    "    fix_lines = re.sub(re2, \"\\n\", fix_lines).replace(\"or,\", \",\")  # correct the common edge cases\n",
    "    lines = re.sub(regex, \"\", fix_lines).replace(r\"﻿\", \"\").split(\"\\n\")  # remove the formatting, split by line\n",
    "\n",
    "    new_lines = []  # Used to determine what the new lines will be\n",
    "    drop_lines = []  # Used to determine which lines to remove from the set\n",
    "\n",
    "    # Recreate the phoneme-word list object separating by the comma from the CSV file\n",
    "    for line in lines:\n",
    "        split_lines = line.split(\",\")\n",
    "        if len(split_lines) == 2:  # Only add the line to new_lines if they are the correct size\n",
    "            new_lines.append(split_lines)\n",
    "\n",
    "        else:\n",
    "            drop_lines.append(line)  # Remove the line otherwise\n",
    "\n",
    "    # Remove each element in drop_lines from the original lines list for processing\n",
    "    for line in drop_lines:\n",
    "        lines.remove(line)\n",
    "\n",
    "    remove_lines = []  # Lines to remove from the current dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    Remove any elements with phonetics that looks suspicious.\n",
    "    These elements are not within 3 characters of length when compared to the original word.\n",
    "    Remove the term if the line is less than 60% of the original length as well, that would imply a 40% reduction\n",
    "    in length from word to phoneme and is uncommon in the english language.\n",
    "    \"\"\"\n",
    "    for new_line in new_lines:\n",
    "        if len(new_line) == 2 and\n",
    "                (len(new_line[0]) < (.6 * len(new_line[1])) or len(new_line[0]) > (len(new_line[1]) + 3)):\n",
    "            remove_lines.append(new_line)\n",
    "\n",
    "        # Lines to remove from the list of words.\n",
    "        elif not len(new_line) == 2:\n",
    "            remove_lines.append(new_line)\n",
    "\n",
    "        else:\n",
    "            # Try to resolve another known edge case\n",
    "            non_abc = re.match(r\"[a-zA-Z]*[^a-zA-Z\\d\\s:][a-zA-Z]*\", new_line[1])\n",
    "            # If the match did not occur, ignore this element.\n",
    "            if non_abc:\n",
    "                print(non_abc.group(0))\n",
    "                remove_lines.append(new_line)\n",
    "\n",
    "    remove_set = set()  # Set of items to be removed\n",
    "    remove_lines = remove_lines[:len(remove_lines) - 1]  # Removes the empty set.\n",
    "    not_found = codecs.open(err_filename, \"a\")  # Add all not found elements to the list of error 404s.\n",
    "\n",
    "    for remove in remove_lines:\n",
    "        #For each line that was successfully added, attempt to add it to the 404s list\n",
    "        try:  # This is a case where both words exist, but for some reason the word is unacceptable\n",
    "            remove_set.add(str(remove[0]) + \",\" + str(remove[1]))\n",
    "            not_found.write(str(remove[1]) + \"\\n\")\n",
    "            print(\"Removed: \" + remove[1])\n",
    "            new_fails += 1\n",
    "\n",
    "        except:\n",
    "            try:  # If that case fails, there is another case where the second element does not exist\n",
    "                print(remove[0])\n",
    "                remove_set.add(str(remove[0]))\n",
    "                not_found.write(str(remove[0]) + \"\\n\")\n",
    "                new_fails += 1\n",
    "\n",
    "            except:\n",
    "                # If this term's formatting is bad, print this did not work and add it to the list of 404s.\n",
    "                print(\"This did not work\")\n",
    "                error = codecs.open(\"weird_words.txt\", \"a\", \"utf-8-sig\")\n",
    "                error.write(str(remove))\n",
    "                error.close()\n",
    "\n",
    "    not_found.close()\n",
    "\n",
    "    # Final set is the set of words remaining to be acquired.\n",
    "    final_set = set(lines) - remove_set - set([\"\"]) - set([\"phonemes,graphemes\\n\"])\n",
    "    purged = init_length - len(final_set)  # the difference between start and end lengths is the number purged.\n",
    "\n",
    "    print(\"Total_Purged:\\t\\t\" + str(purged))  #Can be used for debugging or progress verification.\n",
    "\n",
    "    # Empty the phoneme-words file, and write the headers, \"phonemes and graphemes\" to the file first\n",
    "    end_block = codecs.open(write_file, \"w\", \"utf-8-sig\")\n",
    "    end_block.write(\"phonemes,graphemes\\n\")\n",
    "\n",
    "    # Write each of the remaining words, which should have good formatting, in final_set to the phonemes-words list.\n",
    "    for line in final_set:\n",
    "        end_block.write(str(line).lower() + \"\\n\")\n",
    "    end_block.close()\n",
    "\n",
    "    # Reopen the error file, parse the terms in it, create a set.\n",
    "    error_file = codecs.open(err_filename, \"r\", \"utf-8-sig\")\n",
    "    err = set(error_file.read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "    error_file.close()\n",
    "\n",
    "    global dict_list, curr_words\n",
    "    # Get the set of the list of words fro from final set\n",
    "    curr_words = set([word.split(\",\")[1] for word in final_set])\n",
    "    dict_list = list((set(dict_list) - curr_words) - err)  # Update the global list of remaining words\n",
    "    return final_set  # Return the set of words remaining in the phonemes-words csv\n",
    "\n",
    "\n",
    "times_phon_was_run = 0  # Number of times the phon function was run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Execute the main data-gathering function\n",
    "Before starting to acquire data we always want to make sure that we have all data needed in the correct form, so we\n",
    "run\n",
    "\"remove invalids\" before acquiring any new data. Then we acquire as much data as we need to reach \"original size\"\n",
    "phon is the main function used to acquire new phonetics and consists of the functions above. Phon allows you to\n",
    "acquire data in \"groups\" of size \"group_size\" which will run remove_invalids() every time group size is reached to\n",
    "eliminate the likelihood that data that was acquired is repeated by using random words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def phon(size):\n",
    "    \"\"\"\n",
    "    The main key function used to request and process size number of word-phonetics.\n",
    "    This function will only be called once every time \"size\" has been reached.\n",
    "\n",
    "    :param size: the number of elements to retrieve phonetics for\n",
    "    :type size: int\n",
    "    \"\"\"\n",
    "    # access the global class variables\n",
    "    global new_size\n",
    "    global times_phon_was_run\n",
    "    global words_added, total_failed, dict_list, dict_file\n",
    "\n",
    "    # Set both words added and total failed to 0\n",
    "    words_added = total_failed = 0\n",
    "    group_size = 1000  # How many webpages to scrape before updating 404s and the words_beta word list.\n",
    "    new_size = size\n",
    "\n",
    "    times_phon_was_run += 1  # Used in debugging to track number of times this function is called.\n",
    "    # print(\"Again: \" + str(times_phon_was_run)) # Used in debugging to track number of times this function is called.\n",
    "    rounds = int(size / group_size)  # The number of times to acquire group_size elements to reach size\n",
    "\n",
    "    for i in range(rounds):\n",
    "        # print(\"Round: \" + str(i))\n",
    "        urls = get_urls(group_size)  # get a list of group_size urls with words from words_beta\n",
    "        get_all(urls)  # concurrently acquire size number of urls, downloading up to 20 urls at a time\n",
    "        remove_invalids()  # remove any and all invalid elements\n",
    "\n",
    "    urls = get_urls(size - rounds * group_size)  # acquire remaining urs, since there will likely be a remainder.\n",
    "    get_all(urls)  # get all of the remaining urls after all group sizes have been reached.\n",
    "\n",
    "\n",
    "fixed_set = remove_invalids()  # Removes around 99.9% of current invalid lines before attempting to acquire new words\n",
    "phon(new_size + total_failed)  # Run the main function\n",
    "fixed_set = remove_invalids()  # Remove invalids returns all items currently in the phonetics list\n",
    "\n",
    "# Keep repeating the process of getting phoneme_words until all phonetics are reached.\n",
    "while len(fixed_set) < original_size:\n",
    "    phon(original_size - len(fixed_set))\n",
    "    fixed_set = remove_invalids()  # remove invalid phoneme-words and update lists of words\n",
    "\n",
    "# Log the total time the function took to run.\n",
    "total_time = time.time() - start_time\n",
    "print(total_time)\n",
    "\n",
    "# Store the time in the timing document, used to optimize the functions and decrease runtime.\n",
    "time_file = codecs.open(\"conc_timing.txt\", \"a\")\n",
    "time_file.write(str(total_time) + \"\\n\")\n",
    "time_file.close()\n",
    "\n",
    "# Update the words_beta.txt and error by subtracting all words that do not work.\n",
    "a_dict = set(codecs.open(\"words_alpha.txt\", \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "b_write = codecs.open(dict_filename, \"w\", \"utf-8-sig\")\n",
    "err = set(codecs.open(err_filename, \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "err_write = codecs.open(err_filename, \"w\", \"utf-8-sig\")\n",
    "\n",
    "new_dict_set = a_dict - err  # Subtract the set of errors from the beta dictionary\n",
    "\n",
    "# Write each line back to the beta file\n",
    "for word in new_dict_set:\n",
    "    b_write.write(word + \"\\n\")\n",
    "\n",
    "# Write each error back to the error file\n",
    "for errors in err:\n",
    "    err_write.write(errors + \"\\n\")\n",
    "\n",
    "# Close out the file\n",
    "b_write.close()\n",
    "err_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Building the model\n",
    "\n",
    "Now we will discuss building and training the model. First well do a bit of setup, importing libraries and computing vocabularies for phonemes and graphemes. A vocabulary is a set of known tokens corresponding, in our case, to phoneme or grapheme tokens. The grapheme list will just be the English alphabet, but there are many more phonemes in the International Phonetic Alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', 'k', 'y', 'ʊ', 'r', 'ɑ', 'a', 'ɪ', 'z', 'æ', 't', 'ə', 'b', 'n', 'u', 'l', 'm', 'ɛ', 'd', 'e', 'ʃ', 's', 'ʌ', 'g', 'f', 'o', 'θ', 'ɒ', 'i', 'ʒ', 'p', 'ɔ', 'v', 'ː', 'h', 'ŋ', 'w', '̃', 'ɡ', 'j', 'ɜ', 'ð', 'ʰ', 'x', 'c', 'œ', 'ü', 'ɘ', 'ø', 'ĩ']\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(0)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "# for logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Compute phoneme/grapheme vocabularies\n",
    "data = pd.read_csv(\"phonemes-words.csv\")\n",
    "phonemes_col = data[\"phonemes\"]\n",
    "graphemes_col = data[\"graphemes\"]\n",
    "# vocabularies contain 0 and 1 as start and end tokens\n",
    "phonemes = ['0', '1']\n",
    "graphemes = ['0', '1']\n",
    "\n",
    "# Get each phoneme within our data\n",
    "for word in phonemes_col:\n",
    "    for phoneme in word:\n",
    "        if phoneme not in phonemes:\n",
    "            phonemes.append(phoneme)\n",
    "\n",
    "# Get each grapheme within our data\n",
    "for word in graphemes_col:\n",
    "    for grapheme in word:\n",
    "        if grapheme not in graphemes:\n",
    "            graphemes.append(grapheme)\n",
    "\n",
    "# wow, there are lot of different phonemes!\n",
    "print(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Thats a lot of phonemes. Hopefully the model can learn all of those 🙂.\n",
    "\n",
    "\n",
    "Now lets define a couple of helper functions to encode and decode phoneme/grapheme strings. Computers can't process letters themselves, so when we feed phonemes and graphemes into the model, we will 1-hot encode them. Well also define a Pytorch Dataset object to efficiently iterate through our dataset at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nemes_to_1_hot_seq(string, nemes=\"phonemes\"):\n",
    "    \"\"\"\n",
    "    One hot encodes the word according to either the phoneme or grapheme list\n",
    "\n",
    "    :returns torch.FloatTensor([seq]): pytorch tensor of one hot encoded characters\n",
    "    \"\"\"\n",
    "    string = '0' + string + '1'\n",
    "    list = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    seq = []\n",
    "\n",
    "    for i in string:\n",
    "        vec = [0] * len(list)\n",
    "        vec[list.index(i)] = 1\n",
    "        seq.append(vec)\n",
    "\n",
    "    return torch.FloatTensor([seq])\n",
    "\n",
    "\n",
    "def one_hot_to_nemes(one_hot, nemes=\"phonemes\"):\n",
    "    \"\"\"\n",
    "    Converts a 1-hot encoding back to characters\n",
    "\n",
    "    :param arr: of one hot encoded characters\n",
    "    :param nemes:\n",
    "\n",
    "    :return seq: sequence of characters\n",
    "    \"\"\"\n",
    "    seq = []\n",
    "    list = phonemes if nemes == \"phonemes\" else graphemes\n",
    "\n",
    "    for hot in one_hot:\n",
    "        x = torch.argmax(hot)\n",
    "        seq.append(list[x])\n",
    "    return seq\n",
    "\n",
    "\n",
    "class P2GDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset object for sampling the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, phoneme_file, device):\n",
    "        \"\"\"\n",
    "        :param phoneme_file: Name of the file where the phonemes are stored\n",
    "        :param device: Whether P2G will be run on cpu or gpu\n",
    "\n",
    "        :type phoneme_file: str\n",
    "        :type device: str\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(phoneme_file)\n",
    "        self.data = df\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an item at index idx\n",
    "\n",
    "        :param idx: index of item to get\n",
    "        :return: phonemes one_hot encoded run on device, graphemes one hot encoded run using long\n",
    "        \"\"\"\n",
    "\n",
    "        p, g = self.data.iloc[idx]\n",
    "        # 1-hot encoding\n",
    "        return nemes_to_1_hot_seq(p, nemes=\"phonemes\").to(self.device), nemes_to_1_hot_seq(g, nemes=\"graphemes\").long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Before getting into the model itself, lets take a look at the data. Our model will read a phonetic spelling (the first column) and attempt to output the corresponding English grapheme (the second column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 78845\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonemes</th>\n",
       "      <th>graphemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kyʊrɑraɪz</td>\n",
       "      <td>curarize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ætəbrɪn</td>\n",
       "      <td>atebrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>butlɪk</td>\n",
       "      <td>bootlick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mɛndeɪʃəs</td>\n",
       "      <td>mendacious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lʌgər</td>\n",
       "      <td>lugger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ludnɪs</td>\n",
       "      <td>lewdness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nɛfroʊlɪθɒtəmi</td>\n",
       "      <td>nephrolithotomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dʒaɪənt</td>\n",
       "      <td>giant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>maɪkroʊb</td>\n",
       "      <td>microbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dɑrnər</td>\n",
       "      <td>darner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pɒtsəlænɪk</td>\n",
       "      <td>pozzolanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>proʊθɔræks</td>\n",
       "      <td>prothorax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sʌbsɪdi</td>\n",
       "      <td>subsidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ripəzɪʃən</td>\n",
       "      <td>reposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>əfloʊt</td>\n",
       "      <td>afloat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          phonemes        graphemes\n",
       "0        kyʊrɑraɪz         curarize\n",
       "1          ætəbrɪn          atebrin\n",
       "2           butlɪk         bootlick\n",
       "3        mɛndeɪʃəs       mendacious\n",
       "4            lʌgər           lugger\n",
       "5           ludnɪs         lewdness\n",
       "6   nɛfroʊlɪθɒtəmi  nephrolithotomy\n",
       "7          dʒaɪənt            giant\n",
       "8         maɪkroʊb          microbe\n",
       "9           dɑrnər           darner\n",
       "10      pɒtsəlænɪk       pozzolanic\n",
       "11      proʊθɔræks        prothorax\n",
       "12         sʌbsɪdi          subsidy\n",
       "13       ripəzɪʃən       reposition\n",
       "14          əfloʊt           afloat"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Whether to run on cuda or cpu\n",
    "dataset = P2GDataset(\"phonemes-words.csv\", device)  # initialize our dataset to be run on \"device\"\n",
    "print(\"Size of dataset: \" + str(len(dataset)))\n",
    "dataset.data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets graph word lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the frequency of words within our dataset that have each existing word length\n",
    "dict = {}\n",
    "for index in range(len(dataset.data)):\n",
    "    phnme, grphme = dataset.data.iloc[index]\n",
    "\n",
    "    if len(grphme) in dict:\n",
    "        dict[len(grphme)] += 1\n",
    "    else:\n",
    "        dict[len(grphme)] = 1\n",
    "\n",
    "Y = []\n",
    "for char in dict.keys():\n",
    "    Y.append(dict[ele])\n",
    "\n",
    "# Plot the distribution of word lengths as a frequency plot.\n",
    "X = dict.keys()\n",
    "fig = plt.figure()\n",
    "plt.bar(X, Y, 0.4, color=\"green\")\n",
    "plt.xlabel(\"Length of Word\")\n",
    "plt.ylabel(\"# of Words\")\n",
    "plt.title(\"# of Words of Different Lengths\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the distribution of lengths of words in the dataset. It looks like a normal with a slight leftward skew. The median word length is around 8, which happens to be the sequence length that vanilla seq2seq (e.g. Cho et al) implementations experience signifigant performance degrading. We will use a more complex architecture to hopefully deal with this, and we should expect best performance on words of length 8 since our data is concentrated there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets graph letter densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the percentage distribution of letters (graphemes)\n",
    "dict = {}\n",
    "for index in range(len(dataset.data)):\n",
    "    phnme, grphme = dataset.data.iloc[index]\n",
    "    lowString = grphme.lower()\n",
    "\n",
    "    # Increment frequency of character by one\n",
    "    for char in lowString:\n",
    "        if char in dict:\n",
    "            dict[char] += 1\n",
    "        # Add the character to the list and initialize as 1\n",
    "        else:\n",
    "            dict[char] = 1\n",
    "\n",
    "Y = []\n",
    "# Calculate the percent for each element\n",
    "for ele in dict.keys():\n",
    "    Y.append(dict[ele] / len(dataset.data))\n",
    "\n",
    "# Plot each element using the original dict keys as the X value and the Y as the percentage per character.\n",
    "X = dict.keys()\n",
    "fig = plt.figure()\n",
    "plt.bar(sorted(X), Y, 0.4, color=\"green\")\n",
    "plt.xlabel(\"letter\")\n",
    "plt.ylabel(\"Average Number of Occurrences in a Word\")\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows the average amount of each letter in words in the dataset. No letter occurs more than once on\n",
    "average,  but \"g\" is quite close. We would not expect any letters to occur more than once on average considering that\n",
    "the average word length is 8, but there are 26 grapheme characters. The surplus of \"g\"s is surprising and the unequal\n",
    "distribution of letters may lead to the model overpredicting \"g\"s. \"h\" occurs frequently, but \"f\" does not, so\n",
    " perhaps we will see strange spellings of the \"f\" sound, such as the well known example of \"fish\" being spelled as\n",
    " \"ghoti\" (\"gh\" produces the f sound as in laugh, \"o\" produces the \"ih\" sound as in women, and \"ti\" produces the shh\n",
    " sound as in potion). 🙂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "We tested many varieties of RNNs for this project. We tried the following combinations:\n",
    "\n",
    "Single layer GRU encoder+decoder\n",
    "\n",
    "Double/Triple stacked GRU encoder+decoder\n",
    "\n",
    "Single layer LSTM encoder+decoder\n",
    "\n",
    "We also varied hidden sizes, testing 512 or 1024\n",
    "\n",
    "We settled on the following architecture (hidden size 512):\n",
    "\n",
    "Double stacked bidirectional GRU encoder -> linear layer which accepts the last forward/backward hidden layers and converts them to a vector the size of a single hidden layer -> unstacked unidirectional GRU decoder with Bahdanau attention.\n",
    "\n",
    "## Reasoning\n",
    "Why did we choose these neural network combinations, and what were their results? <br>\n",
    "We chose these neural network types because we needed RNNs perform well with sequential data. We decided we needed more complex RNNs (e.g. LSTMs, GRUs as opposed to a vanilla Elman RNN) with cell states in order to deal with the complex and potentially long input sequences. Accuracy for these models generally sat around 30% on the test set. This means that 30% of words get spelled exactly correctly, but most words are a few characters off.\n",
    "\n",
    "What was our strategy for increasing accuracy? <br>\n",
    "\n",
    "We tried using deeper models, stacking GRUs, testing LSTMs, and introducing attention. Bahdanau attention was able to boost test test performance to 50% accuracy, a big step.\n",
    "\n",
    "What else could we do to increase the accuracy? <br>\n",
    "State of the art work on G2P for English (the opposite of our task) uses transformers. This would be the next step for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hidden layer size\n",
    "layer_size = 512\n",
    "\n",
    "\n",
    "# define model architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(len(phonemes), layer_size, 2, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        # Set up the encoder's fully connected (fc) variable as a sequential neural network\n",
    "        self.fc = nn.Sequential(\n",
    "            # takes final forwards and backwards hidden states as parameters\n",
    "            nn.Linear(2 * layer_size, layer_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, vector):\n",
    "        \"\"\"\n",
    "        Push vector through encoder\n",
    "\n",
    "        :param vector:\n",
    "        :return out, hidden_for_init: context vector\n",
    "        \"\"\"\n",
    "        # out is the output of the encoder neural network\n",
    "        # hidden is [4, 1, layer_size]\n",
    "        # this is because of bidirectionality * double stacked\n",
    "        out, hidden = self.encoder(vector)\n",
    "\n",
    "        # we want to grab the \"highest\" layers from the forwards and backwards directions\n",
    "        # dim 1 because hidden[3] and hidden[4] are both [1, layer_size] and we\n",
    "        # want a single batch that has 2*layer_size values\n",
    "        hc = torch.cat((hidden[2], hidden[3]), dim=1)\n",
    "        # pass the hidden concatenated (hc) layers to the fully connected neural network\n",
    "        hidden_for_init = self.fc(hc)\n",
    "\n",
    "        # return context vector\n",
    "        return out, hidden_for_init\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2 from encoder state and 1 from decoder state (since not bidirectional)\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(3 * layer_size, layer_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # map energy vectors to single values\n",
    "        self.attention = nn.Linear(layer_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_hiddens, decoder_hidden):\n",
    "        \"\"\"\n",
    "        Feed forward neural network\n",
    "\n",
    "        :param encoder_hiddens: is [1, L, layer_size*2] because it is bidirectional\n",
    "        :param decoder_hidden:is [1, layer_size]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # 1 bc using batch first\n",
    "        num_encoder_hiddens = encoder_hiddens.shape[1]\n",
    "        # make it [1,1,layer_size]\n",
    "        decoder_hidden = torch.unsqueeze(decoder_hidden, 0)\n",
    "        # repeat along second dim to get [4, 1, layer_size]\n",
    "        decoder_hiddens = decoder_hidden.squeeze(0).repeat(1, num_encoder_hiddens, 1)\n",
    "\n",
    "        inputs = torch.cat((encoder_hiddens, decoder_hiddens), 2)\n",
    "        energy = self.energy(inputs)\n",
    "        attention = self.attention(energy)\n",
    "\n",
    "        # we want a distribution of attention that sums to 1, so we use the nn.functional softmax function\n",
    "        return F.softmax(attention, dim=2)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        \"\"\"\n",
    "        :param attention: the attention module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        # decoder GRU takes in previous output word, attention vector, current hidden state\n",
    "        self.decoder = nn.GRU(len(graphemes) + 2 * layer_size, layer_size, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(layer_size * 3 + len(graphemes), len(graphemes))\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden_layer, encoder_hiddens):\n",
    "        \"\"\"\n",
    "        Since this function gets called once at a time rather than taking in\n",
    "        a sequence of vectors, we need to pass it the last output. This will be just\n",
    "        a vector of numbers that can be converted to the embedding representing that last output\n",
    "\n",
    "        :param input: vector of numbers that can be converted to the embedding representing that last output\n",
    "        :param hidden_layer: [1,1,layer_size]\n",
    "        :param encoder_hiddens: [1,L,layer_size]\n",
    "        \"\"\"\n",
    "        attention_vals = self.attention(encoder_hiddens, hidden_layer)\n",
    "        attention_vals = attention_vals.permute(0, 2, 1)\n",
    "\n",
    "        # and sums the weighted vectors\n",
    "        # will be [1, 1, layer_size]\n",
    "        # bmm multiplies matrix-matrix products, which multiplies each attention value against the appropriate vector\n",
    "        # and sums the weighted vectors\n",
    "        attended = torch.bmm(attention_vals, encoder_hiddens)\n",
    "        input = torch.cat((attended, input), dim=2)\n",
    "        out, hidden = self.decoder(input, hidden_layer)\n",
    "        # out[1] to get top hidden layer\n",
    "        input_for_fc = torch.cat((input, out), dim=2)\n",
    "\n",
    "        return self.fc(input_for_fc), hidden\n",
    "\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    \"\"\"\n",
    "    The seq2seq model itself\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        # instantiate encoder and decoder with attention\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(Attention())\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, in_seq, out_seq, tf_ratio=0.5):\n",
    "        \"\"\"\n",
    "        :param in_seq:\n",
    "        :param out_seq:\n",
    "        :param tf_ratio: is the teacher forcing ratio. It decides how frequently\n",
    "        the model receives its own previously predicted token as opposed to the\n",
    "        known correct token.\n",
    "        \"\"\"\n",
    "        out_len = out_seq.shape[1]\n",
    "        # storing the outputs of the sequence\n",
    "        outputs = torch.zeros(out_len, 1, len(graphemes)).to(self.device)\n",
    "\n",
    "        out_for_at, hidden = self.encoder(in_seq)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "\n",
    "        # perform an embarassing amount of data conversions\n",
    "        input = out_seq[0].unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # for each token in known out sequence (except the first)\n",
    "        for i in range(1, out_len):\n",
    "            out, hidden = self.decoder(input, hidden, out_for_at)\n",
    "            outputs[i] = out\n",
    "\n",
    "            if random.random() > tf_ratio:\n",
    "                # teacher forcing (make next input what the current output token should be)\n",
    "                input = out_seq[i].unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            else:\n",
    "                # use previously output token\n",
    "                x = input.argmax(1)[0]\n",
    "                input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "                input[0][0][x] = 1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def pred_new(self, in_seq):\n",
    "        \"\"\"\n",
    "        Method to predict the output sequence for a previously unseen\n",
    "        input sequence. The main difference between this function and forward\n",
    "        is that this function only stops decoding when the model produces an\n",
    "        end token.\n",
    "\n",
    "        :param in_seq:\n",
    "        :return: decoded outputs from the neural network\n",
    "        \"\"\"\n",
    "        encoder_out_for_at, hidden = self.encoder(in_seq)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "        outs = []\n",
    "\n",
    "        while True:\n",
    "            out, hidden = self.decoder(input, hidden, encoder_out_for_at)\n",
    "            outs.append(out)\n",
    "\n",
    "            # in case not hitting end token\n",
    "            if len(outs) > 50:\n",
    "                break\n",
    "\n",
    "            x = input.argmax(1)[0]\n",
    "            input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "            input[0][0][x] = 1\n",
    "\n",
    "            # end token used to stop decoding the model\n",
    "            if one_hot_to_nemes(out) == ['1']:\n",
    "                break\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ready to train\n",
    "\n",
    "Now that we have a beautiful architecture, we need to instantiate it as well as a loss function and an optimizer. We use cross entropy loss since the model outputs a \"class\" (one of a number of possible tokens) at each decoding step. We'll also use Adam, since more vanilla optimizers (e.g. SGD or SGD+momentum) will tend not to converge on a network this complex.\n",
    "\n",
    "We perform a ~90%-10% train test split. The following code includes a couple of functions for computing and displaying the 0-1 accuracy of the model. 0-1 accuracy counts only the words which the model gets exactly correct.\n",
    "\n",
    "Note that hyperparameters were tuned by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture  seq2seq(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): GRU(51, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): Attention(\n",
      "      (energy): Sequential(\n",
      "        (0): Linear(in_features=1536, out_features=512, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "      (attention): Linear(in_features=512, out_features=1, bias=False)\n",
      "    )\n",
      "    (decoder): GRU(1052, 512, batch_first=True)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1564, out_features=28, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "train size  70000\n",
      "test size  8845\n"
     ]
    }
   ],
   "source": [
    "# initialize optimizer/loss func/hyperparams\n",
    "EPOCHS = 15\n",
    "model = seq2seq(device).to(device)  # Model used to train on the data.\n",
    "# what a beautiful architecture\n",
    "print(\"Model architecture \", model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# train on 70000 words\n",
    "train, test = random_split(dataset, [70000, len(dataset) - 70000])\n",
    "dataloader = DataLoader(dataset=train, batch_size=1)\n",
    "print(\"train size \", len(train))\n",
    "print(\"test size \", len(test))\n",
    "\n",
    "\n",
    "def get_0_1_accuracy(test_set, model, print=True):\n",
    "    \"\"\"\n",
    "    method to compute (1 - WER) accuracy AKA what % of test_set does model get\n",
    "    exactly correct.\n",
    "\n",
    "    :param test_set: set of phoneme-words used to predict word accuracy\n",
    "    :param model:\n",
    "    :param print:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        true = \"\".join(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))[1:-1]\n",
    "        print(true)\n",
    "        pred = \"\".join(one_hot_to_nemes(prediction, \"graphemes\"))[0:-1]\n",
    "        print(pred)\n",
    "\n",
    "        if true == pred:\n",
    "            correct += 1\n",
    "\n",
    "    if correct == 0:\n",
    "        return correct\n",
    "    return correct / len(test_set)\n",
    "\n",
    "\n",
    "def gen_accuracy_plot(real, pred, title):\n",
    "    \"\"\"\n",
    "    Gnerates and displays a plot of performance on\n",
    "    different lengths of words\n",
    "\n",
    "    :param real: The actual correct word\n",
    "    :param pred: The predicted correct word\n",
    "    :param title: Title of the plot\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = {}\n",
    "    dict = {}\n",
    "\n",
    "    for i in range(len(real)):  # (iterate through all elements in real)\n",
    "        if real[i] == pred[i]:  # If the elements match then\n",
    "            if len(real[i]) in accuracy:  # if the length of the element is in dictionary \"accuracy\"\n",
    "                accuracy[len(real[i])] += 1  # add 1 to the length of the element\n",
    "            else:\n",
    "                accuracy[len(real[i])] = 1  # otherwise add the length as a new element starting from 1\n",
    "        else:  # if the real element does not match then\n",
    "            if len(real[i]) not in accuracy:  # If the length of the real element is not in accuracy\n",
    "                accuracy[len(real[i])] = 0  # add the length as a new element starting from 0\n",
    "\n",
    "        if len(real[i]) in dict:  # if the length is already in dictionary, \"dict\"\n",
    "            dict[len(real[i])] += 1  # add one to that length\n",
    "        else:\n",
    "            dict[len(real[i])] = 1  # otherwise add a new element for that length beginning from one\n",
    "    X = dict.keys()  # get all of the total elements with each length\n",
    "    Y = []\n",
    "\n",
    "    for i in X:  # add each total correct element as a float to the list Y and divide by the total number of elements for that length\n",
    "        Y.append(1.0 * accuracy[i] / dict[i])\n",
    "    plt.bar(X, Y, 0.4, color=\"green\")\n",
    "    plt.xlabel(\"Length\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of model parameters:  10221868\n"
     ]
    }
   ],
   "source": [
    "print(\"# of model parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wow, 10 million params! This model has more trainable parameters than tonnes of potatoes France produced in 2016! (absolutely no semantic relation). This might take a while to train, so make sure to use a NVIDIA GeForce RTX 3090 Ti 🙂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Our training loop is quite simple. We use a batch size of 1, so as not to deal with padding/packing. We record a couple metrics like loss and current accuracy on the test set as the model progresses. This part will likely take a while to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"tensorboard_data\")\n",
    "# get a mini testing batch to check model accuracy on the test set\n",
    "# throughout training\n",
    "# NOTE: this is not a validation set\n",
    "mini_test, _ = random_split(test, [20, len(test) - 20])\n",
    "\n",
    "# begin training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        # batch size of 1\n",
    "        in_seq = in_seq.squeeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "        # perform inference\n",
    "        model_output = model(in_seq, out_seq)\n",
    "        # dont compute loss using first token of in/out sequence\n",
    "        model_output = model_output[1:]\n",
    "        model_output = model_output.squeeze(1)\n",
    "        out_seq = out_seq.squeeze(0)[1:]\n",
    "        # compute loss\n",
    "        loss = loss_func(model_output, out_seq.argmax(1).to(device))\n",
    "        # record loss\n",
    "        tot_loss += loss.detach().item()\n",
    "        # accumulate gradients\n",
    "        loss.backward()\n",
    "        # step and clear grads\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    tot_loss /= len(train)\n",
    "    # record current accuracy on test set and average loss\n",
    "    writer.add_scalar(\"tensorboard_data/acc\", get_0_1_accuracy(mini_test, model), epoch)\n",
    "    writer.add_scalar(\"tensorboard_data/loss\", tot_loss, epoch)\n",
    "torch.save(model, \"THEMODEL60%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plasma\n",
      "plasma\n",
      "obligatory\n",
      "obbigatory\n",
      "sciosophy\n",
      "scyosophy\n",
      "inning\n",
      "inning\n",
      "ecchymosis\n",
      "echmocisis\n",
      "tailspin\n",
      "tailspin\n",
      "eudiometry\n",
      "eudiometry\n",
      "acetanilide\n",
      "acetanilidd\n",
      "interlineate\n",
      "interleneate\n",
      "dizygotic\n",
      "disiggtii\n",
      "heptad\n",
      "heptad\n",
      "gadhelic\n",
      "gadhellc\n",
      "wellaway\n",
      "wellaway\n",
      "jesu\n",
      "jeauu\n",
      "boatsman\n",
      "boaesman\n",
      "blazon\n",
      "blazonn\n",
      "particularize\n",
      "particularize\n",
      "particulurize\n",
      "pure\n",
      "pure\n",
      "lusatian\n",
      "lusatian\n",
      "canonicate\n",
      "canonicate\n",
      "Test accuracy: 0.5847371396269079\n"
     ]
    }
   ],
   "source": [
    "# load model onto cpu\n",
    "model = torch.load(\"THEMODEL60%\", map_location=torch.device('cpu')).to(torch.device('cpu'))\n",
    "model.device = \"cpu\"\n",
    "# turn dropout off\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Test accuracy: \" + str(get_0_1_accuracy(test, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well that accuracy is... disappointing. It might be better than the average human (when faced with 10s of thousands\n",
    "of rare words), but that's still a lot of errors.\n",
    "What is the reason for this?\n",
    "Even though the attention module should, in theory, allow the model to be much more performant, the English language\n",
    "is rife with inconsistent spelling and pronunciation rules. Additionally, some words (e.g. their, they\\re, there) are pronounced the same, so the model does not have enough information to distinguish between them. One more confounding factor is that the phonemes we are using are from the International Phonetic Alphabet, so are not as specific to the English language as the Carnegie Melon pronunciation dictionary ARPAbet (an English prononciation specification). Thus, the model needs to learn more complex rules, especially considering that there are more distinct phonemes in IPA than in ARPAbet. However, our use of IPA in theory allows better spelling on non-English words.\n",
    "\n",
    "What can we do about this poor performance? We can see a couple cells up that the model is generally off by just a few grapheme characters. Hopefully you are already thinking along the lines of spellcheck 🙂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![alt text](secret_ingredient.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function similar to the 0_1_accuracy function above, but this one just returns the lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred_lists(test_set, model):\n",
    "    \"\"\"\n",
    "    Returns a list of correct outputs and a corresponding list of model predictions\n",
    "\n",
    "    :param test_set:\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    trues = []\n",
    "    preds = []\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        true = \"\".join(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))[1:-1]\n",
    "        trues.append(true)\n",
    "        pred = \"\".join(one_hot_to_nemes(prediction, \"graphemes\"))[0:-1]\n",
    "        preds.append(pred)\n",
    "\n",
    "    return trues, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import a spellcheck library and give it our known grapheme spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "dict_filename = \"words_beta.txt\"  # `Name of the file containing many words - error\n",
    "err_filename = \"404s.txt\"  # List of all of the known error words\n",
    "\n",
    "dict_file = open(dict_filename).read()\n",
    "dict_list = dict_file.split(\"\\n\")\n",
    "\n",
    "a_dict = set(codecs.open(\"words_alpha.txt\", \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "err = set(codecs.open(err_filename, \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "\n",
    "spellcheck = SpellChecker().correction\n",
    "\n",
    "\n",
    "# Only spell check incorrect strings\n",
    "def spellcheck_1(string):\n",
    "    \"\"\"\n",
    "\n",
    "    :param string:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    spellchecked = string\n",
    "\n",
    "    # Check if the presented string is in the list of known words\n",
    "    if not string in a_dict:\n",
    "        # Attempt to autocorrect the word\n",
    "        spellchecked = spellcheck(\"\".join(string))\n",
    "        # print(\"new_word: \" + spellchecked)\n",
    "    return spellchecked\n",
    "\n",
    "\n",
    "trues, preds = get_true_pred_lists(test, model)\n",
    "\n",
    "\n",
    "def spellcheck_all(str_list):\n",
    "    \"\"\"\n",
    "\n",
    "    :param str_list:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_list = [None] * len(str_list)\n",
    "    str_list = list(str_list)\n",
    "\n",
    "    for i in range(len(str_list)):\n",
    "        new_list[i] = spellcheck_1(str_list[i])\n",
    "\n",
    "    # print(\"original list: \" + str(new_list))\n",
    "    return new_list\n",
    "\n",
    "\n",
    "def get_0_1_accuracy_with_lists(trues, preds):\n",
    "    \"\"\"compute 0 1 accuracy between true and pred lists of words\"\"\"\n",
    "    correct = 0\n",
    "    for (true, pred) in zip(trues, preds):\n",
    "        if pred == true:\n",
    "            correct += 1\n",
    "    return correct / len(trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_checked_words = spellcheck_all(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5847371396269079\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(get_0_1_accuracy_with_lists(trues, preds))\n",
    "gen_accuracy_plot(trues, preds, \"Accuracy on Different Word Lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676088185415489\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(get_0_1_accuracy_with_lists(trues, spell_checked_words))\n",
    "gen_accuracy_plot(trues, spell_checked_words, \"Accuracy on Different Word Lengths (With spellcheck)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! we got a +10% accuracy boost using spellcheck.\n",
    "\n",
    "We hope you enjoyed this journey through the highs and lows of data collection and model training 🙂.\n",
    "\n",
    "## Concluding Remarks\n",
    "With our limited resources, we were able to achieve a total phoneme to grapheme prediction accuracy of 67.6%. With more\n",
    " time, research, computation power, and data we believe we can significantly increase the prediction accuracy. However,\n",
    " with our current system and limited time, we are already able to predict more than two-thirds of words we found that\n",
    "  are\n",
    " not contained within our dataset. In the future, we would like to acquire more data and standardize our phonetics\n",
    " acquired from multiple dictionaries to create a massive library to train our model on. We expect this data increase to\n",
    " increase\n",
    " the overall accuracy of this for use with future word prediction models.\n",
    " <br>\n",
    " <br>\n",
    "Our model is standardized in such a way that a similar method could be used to predict words in systems that also use\n",
    " similar phonetics. This would allow for researchers around the world to use our system, replace the dictionary with\n",
    " a local dictionary, and  produce similar results with minimal changes to the code. After we have increased the\n",
    " accuracy, we plan to map spoken pronunciations to their respective phonemes to apply this technique to more\n",
    " accurately generate words that do not exist in a system's database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Additional Resources\n",
    "If the reader would like more resources related to this topic:\n",
    "\n",
    "For learning the basics of RNNs, LSTMs, GRUs, attention (including Bahdanau), and seq2seq architectures, these resources are good:\n",
    "\n",
    "https://www.deeplearningbook.org/contents/rnn.html\n",
    "\n",
    "https://d2l.ai/chapter_recurrent-modern/seq2seq.html\n",
    "\n",
    "https://d2l.ai/chapter_attention-mechanisms/bahdanau-attention.html\n",
    "\n",
    "For more comprehensive tutorials that walk through the full deep learning process (including varied seq2seq architectures such as transformer), this is a good resource:\n",
    "\n",
    "https://github.com/bentrevett/pytorch-seq2seq\n",
    "\n",
    "These papers discuss grapheme->phoneme conversion with deep learning. This is an easier problem, but still requires complex models for high success rates:\n",
    "\n",
    "https://arxiv.org/abs/2004.06338\n",
    "\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43264.pdf\n",
    "\n",
    "Addtionally, here is a link to Cho et al's foundational seq2seq model paper:\n",
    "\n",
    "https://arxiv.org/abs/1406.1078\n",
    "\n",
    "If the reader is interested in speeding up their programs with concurrency:\n",
    "<br>https://realpython.com/python-concurrency/\n",
    "\n",
    "If the reader would like more information on techniques for web scraping:\n",
    "<br>https://realpython.com/python-web-scraping-practical-introduction/\n",
    "\n",
    "Here is a great introduction to various ideas around phonetics:\n",
    "<br>https://www.britannica.com/science/phonetics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
