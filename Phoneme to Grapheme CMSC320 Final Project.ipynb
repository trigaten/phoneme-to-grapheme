{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <center>Attention Isn't Quite All You Need: Building a Phoneme to Grapheme (P2G) Recurrent Generative Conversion Model from Scratch with GRUs, Attention, and a Little Bit of Subterfuge </center>\n",
    "### <center> Sander Schulhoff, Ryan Brown, Xinyi Liu </center>\n",
    "\n",
    "<center><img src=\"gg.jpg\" alt=\"drawing\" width=\"600\"/></center>\n",
    "\n",
    "<center>\"p2g seq2seq attention model\" by GauGAN</center>\n",
    "\n",
    "### The Importance of Language\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a world where humanity never developed language, would humans still have been able to communicate with the precision required to convey advanced knowledge to other humans? Without language, many of today's inventions and scientific progressions would never have existed. An evolutionary biologist went as far as saying that the creation of language is \"the most important evolutionary invention of the last few million years\" (Nowak 2000). Language allows humans to communicate information with a level of precision that no other animal on earth can replicate. According to psychologists and historians, rational thought can happen without language, but communicating and passing these ideas down through generations are the central tendencies that allow humans to cooperate, develop, and thrive across the globe.\n",
    "\n",
    "The Oxford Dictionary describes linguistics as \"the scientific study of language and its structure, including the study of morphology, syntax, phonetics, and semantics\". From that definition, morphology is the study of words, whose smallest character building blocks are graphemes, and phonetics is the pronunciations of those words and graphemes (Oxford English Dictionary 2021). Most humans can process and recognize words based on their oral pronunciation in their local dialect, but oral communication is not the sole form of communication. In this project, we will be focusing on the importance and applications of oral communication via phonetic spelling in Artificial Intelligence using Recurrent Neural Networks.\n",
    "\n",
    "Our deliverable will be a neural network that can convert the phoneme spelling of a word to its grapheme spelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Why Predict Words and Graphemes?\n",
    "Today's speech recognition systems use varied techniques. However, many of the most commonly used speech recognition systems such as Bixby, Siri, Alexa, and Google do not attempt to spell words outside the system's dictionary. For example, a person's name may be easy to pronounce, but may have unusual spelling. A food's name may be unique and not listed in dictionaries. To give systems like these a boost in their range of responses, we proposed implementing a new system that attempts to predict graphemes from a phoneme spelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Our Project\n",
    "Our project aims to predict graphemes from phonemes. After the completion of our project, the next step would be to map audio to phonemes, which would allow a speaker to say any English word and have the model produce the corresponding spelling. If the model outputs incorrect results, we believe that a robust autocorrect library will frequently correct the attempted word into the correct word. As a result, we believe that converting phonemes to graphemes is a step towards technology having an enhanced ability to recognize speech and produce text that closely resembles the phonetics of speech, providing enhanced communication between users and computational devices and aiding in the evolution of communication.\n",
    "\n",
    "### Webscraping and Cleaning Phonetics\n",
    "We chose to web scrape phonetic spellings from two web sources: merriam-webster.com and dictionary.com. We also attempted to use\n",
    "multiple pdf sources, which did not yield good results. Our code allows for switching between websites by simply\n",
    "adding a new source in the identified code section. However, after reviewing the data, we discovered that dictionary\n",
    ".com produced better and more consistent results, so we decided to choose that website as our sole source of data\n",
    "collection. Unfortunately, the structure of the phonetics section of the web pages was not entirely consistent across\n",
    " different words. This inconsistency required us to write code that handled various new edge cases in order to ensure that\n",
    " our CSV (comma-separated values file) would only contain correct data. We initially used synchronous methods of\n",
    " acquiring data. However, concurrency reduced the program runtime by nearly 75%, as determined by runtime logging. The performance increase allowed us to collect data significantly faster, allowing for a larger dataset and better finetuning of our model. As a result, we acquired over 78,000 phoneme-grapheme combinations for use with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Necessary Imports\n",
    "For scraping, we import several packages:\n",
    "\n",
    "\"OS\" to make sure this code works on various operating systems <br>\n",
    "\"re\" to search and match regular expressions <br>\n",
    "\"NumPy\" for their numerical \"random\" function <br>\n",
    "\"bs4\" for parsing HTML webpages <br>\n",
    "\"codecs\" to have the ability to write unique characters to files using utf-8-sig <br>\n",
    "\"requests\" to request the webpage <br>\n",
    "\"time\" for logging the runtime <br>\n",
    "\"concurrent.futures\" for concurrency <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4\n",
    "import codecs\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures  # This import is important for concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Initialize key variables\n",
    "In order to tailer this file to meet the unique needs of users, we coded several main\n",
    "variablesthat can be interchanged between users. These variables include: website to scrape, the base URL, their list\n",
    " of words to find on the\n",
    "website, a\n",
    "list of all known words with no pages or broken phonetics, the number of words to find, and a list of words that have\n",
    " not yet been attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "codecs.register_error(\"strict\", codecs.ignore_errors)\n",
    "\n",
    "# Basic Background Info\n",
    "headers = {'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X x.y; rv:42.0) Gecko/20100101 Firefox/42.0\"}\n",
    "merriam = \"https://www.merriam-webster.com/dictionary/\"\n",
    "dictionary_web = \"https://www.dictionary.com/browse/\"\n",
    "base_url = dictionary_web  # URL to get words and phonetics from\n",
    "\n",
    "\n",
    "dict_filename = \"words_beta.txt\"  # `Name of the file containing many words - error\n",
    "err_filename = \"404s.txt\"  # List of all of the known error words to eliminate the future chance of choosing those sites\n",
    "\n",
    "# Get current location based on operating system\n",
    "fileDir = os.path.dirname(os.path.realpath('words_beta.txt'))\n",
    "\n",
    "original_size = 1000  # Change this value to change the dataset size and automatically acquire the amount needed\n",
    "new_size = original_size  # Used to subtract the size of any existing sets from the amount needed.\n",
    "\n",
    "# Do the initial parsing of the dictionary file of words that have not yet been attempted.\n",
    "dict_file = open(dict_filename).read()\n",
    "dict_list = dict_file.split(\"\\n\")\n",
    "curr_words = []\n",
    "dict_len = len(dict_list)\n",
    "\n",
    "# Regex required to remove various characters from webscraped strings.\n",
    "regex = r\"( |\\n([a-z][A-Z])*\\n|\\'|\\[|\\]|ˈ|\\+|\\\"|\\(\" \\\n",
    "        r\"|\\)|ˌ||-|͟|¦|\\||‧|͟|&|1|2|–|—|͟|‧|;|pronunciationat|\\r|\\\\|\\/|for\\d*|\\d)*\"\n",
    "to_replace = r\"^noun |^pronoun |^verb |^adjective |^adverb |^preposition |^conjunction |^interjection \"\n",
    "\n",
    "write_file = \"phonemes-words.csv\"  # The file to write phoneme-words to\n",
    "append_or_write = \"a\"  # w to erase write_file and rewrite, a to append to current csv\n",
    "\n",
    "words_added = 0  # Used to keep track of the total number of words added\n",
    "fixed_set = []  # Set of words added to the phonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Initialize intro parameters\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separate the file by lines to retrieve the length\n",
    "if append_or_write == \"a\":\n",
    "    temp_read = codecs.open(write_file, \"r\", \"utf-8-sig\")\n",
    "    new_size -= len(codecs.open(write_file, \"r\", \"utf-8-sig\").read().split(\"\\n\"))\n",
    "    temp_read.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Declare key functions and then run the code to acquire the phonetics efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# This is the main function to get the urls of size \"size\", returns a list of urls pointing dictionary words+phonetics\n",
    "def get_urls(size):\n",
    "    global dict_list\n",
    "    empty_set = set([None])  # Empty set used to remove empty sets from lists\n",
    "    urls = [None] * size  # Indexing the urls using iterators is around 25% faster than appending\n",
    "\n",
    "    # Keep adding numbers until the target size is reached\n",
    "    # print(len(dict_list))\n",
    "    for i in range(size):\n",
    "        new_num = np.random.randint(0, high=len(dict_list))  # Get random number\n",
    "        word = dict_list[new_num]  # Use random number to retrieve word from dictionary\n",
    "\n",
    "        # Changes the base url to include the new word to get that word from the website\n",
    "        modified_url = base_url + word\n",
    "        urls[i] = modified_url\n",
    "\n",
    "    return_set = set(urls) - empty_set  # Remove empty set and duplicates from list of urls\n",
    "\n",
    "    # Keep getting more urls until the size is reached.\n",
    "    while len(return_set) < size:\n",
    "        print(\"Return Set Length: \" + str(len(return_set)))\n",
    "        return_set.update(get_urls(size - len(return_set)))\n",
    "\n",
    "    return return_set # Returns\n",
    "\n",
    "\n",
    "\n",
    "total_failed = 0  # Uses this variable to track number of items that fail.\n",
    "\n",
    "\"\"\"\n",
    "Takes a html page and word as a parameter to parse and retrieve the word on the page and phonetics.\n",
    "\"\"\"\n",
    "def get_word(curr_page, word):\n",
    "    # A commonly used sequence of lines in this method to add the word to list of unavailable words\n",
    "    def add_err():\n",
    "        # Write the word to the not_found list\n",
    "        not_found = codecs.open(err_filename, \"a\")\n",
    "        not_found.write(word + \"\\n\")\n",
    "        not_found.close()\n",
    "\n",
    "        ## This section is used to determine webscraping progress, but is not necessary\n",
    "        global total_failed, words_added # Access these variables to help calculate number remaining.\n",
    "        total_failed -= 1  # Decrement the total fails if the page is unavailable.\n",
    "        print(\"Failed:\\t\\t\\t\" + str(\"\\t\") + \":\\t\\t\" + word) # Print if the word could not be added\n",
    "\n",
    "    if curr_page.status_code == 404:\n",
    "        add_err()  #\n",
    "        # print(\"Error 404\")\n",
    "        # If the page was not valid, try another number combination\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Retrieve the word and phonetics from the page using bs4\n",
    "        if base_url is merriam:\n",
    "            regex1 = r\"( |\\'|\\[|\\]|ˈ|\\+|\\\"|\\(|\\)|ˌ||-|͟|¦|\\||‧|͟|&|–|—|͟|‧|pronunciationat)*\"\n",
    "            web_result = curr_page.content  # Return the new word and page contents\n",
    "            soup = bs4.BeautifulSoup(web_result, \"html.parser\")\n",
    "            word_soup = soup.find_all('h1', {'class': 'hword'})\n",
    "            phonetics = soup.find_all('span', {'class': 'pr'})\n",
    "\n",
    "        else:\n",
    "            regex1 = r\"(ˈ| |/)\"\n",
    "            web_result = curr_page.content  # Return the new word and page contents\n",
    "            soup = bs4.BeautifulSoup(web_result, \"html.parser\")\n",
    "            word_soup = soup.find_all('h1', {'class': 'css-1sprl0b e1wg9v5m5'})\n",
    "            phonetics = soup.find_all('span', {'class': 'pron-ipa-content css-7iphl0 evh0tcl1'})\n",
    "            # print(str(word_soup) + \",\" + str(phonetics))\n",
    "\n",
    "        # Check if both words are of valid lengths\n",
    "        if len(phonetics) >= 1 and len(word_soup) >= 1:\n",
    "            global new_size, total_failed, words_added  # Total number of words added\n",
    "\n",
    "            actual_word = word_soup[0].text.lower()  # Make sure all text is lowercase\n",
    "\n",
    "            # If the word is already in the set, added it to 404s list to avoid repeating terms\n",
    "            # Some words with suffixes and prefixes used only the base word phonetics, causing repeat terms.\n",
    "            if actual_word in curr_words:\n",
    "                add_err()\n",
    "                return\n",
    "            words_added += 1\n",
    "            phonetics = phonetics[0].text.lower()  # Retrieve phonetics\n",
    "\n",
    "            # Some phonetics have multiple pronunciation variations, we only use one\n",
    "            if \",\" or \";\" in phonetics:\n",
    "                phonetics = phonetics.split(\",\")[0].split(\";\")[0]\n",
    "                # print(\"changed p: \" + phonetics)\n",
    "\n",
    "            # Remove all invalid characters\n",
    "            phonetics = re.sub(to_replace, \"\", phonetics)\n",
    "            fixed_phonetics = re.sub(regex1, \"\", phonetics)\n",
    "            # Combine the words into one line for CSV preparation\n",
    "            csv_formatted = fixed_phonetics + \",\" + actual_word\n",
    "\n",
    "            # Write the line to the file.\n",
    "            text_file = codecs.open(write_file, \"a\", \"utf-8-sig\")\n",
    "            text_file.write(csv_formatted + \"\\n\")\n",
    "            text_file.close()\n",
    "\n",
    "            print(\"Words Left:\\t\\t\" + str(new_size - words_added) + \"\\t\\t\" + csv_formatted)\n",
    "\n",
    "            return csv_formatted  # return the formatted string line\n",
    "\n",
    "        else:\n",
    "            # If the adding part does succeed, then add word to error list\n",
    "            add_err()\n",
    "# This method is used to request and process one url at a time\n",
    "def get_one(url):\n",
    "    curr_page = requests.get(url)\n",
    "    get_word(curr_page, url.replace(base_url, \"\"))\n",
    "    return curr_page.raise_for_status()\n",
    "\n",
    "#   The concurrent method used to retrieve all urls at a maximum rate of 20 requests\n",
    "def get_all(urls):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = [executor.submit(get_one, url) for url in urls]\n",
    "\n",
    "    # Log the results and exceptions after the process is completed\n",
    "    for fut in futures:\n",
    "        if fut.exception() is not None:\n",
    "            print('{}: {}'.format(fut.exception(), 'ERR'))\n",
    "        else:\n",
    "            print('{}: {}'.format(fut.result(), 'OK'))\n",
    "\n",
    "\"\"\"\n",
    "This function removes any invalid characters, words, repeat elements, and fixes the formatting of words,\n",
    "accounts for edge cases, and fixes as much data as it can before writing it to the file or removing the data\n",
    "completely if it cannot be fixed.\n",
    "\"\"\"\n",
    "def remove_invalids():\n",
    "    new_fails = 0 # Number of new elements that are removed\n",
    "    read_file = codecs.open(write_file, \"r\", \"utf-8-sig\") # Retrieve the current phonemes-words list\n",
    "    fix_lines = read_file.read() # Read the file\n",
    "    read_file.close()\n",
    "\n",
    "    init_length = len(fix_lines.split(\"\\n\")) # The original number of of phoneme-word combination.\n",
    "\n",
    "    global regex # the regex function written earlier\n",
    "    # Regex to remove common parts of speech accompanying phonetics to be acquired on dictionary.com\n",
    "    re2 = r\"\\n(noun|pronoun|verb|adjective|adverb|preposition|conjunction|interjection)\"\n",
    "    # print(re.findall(re2, fix_lines)) # Used to debug\n",
    "    fix_lines = re.sub(re2, \"\\n\", fix_lines).replace(\"or,\", \",\") # correct the common edge cases\n",
    "    lines = re.sub(regex, \"\", fix_lines).replace(r\"﻿\", \"\").split(\"\\n\") # remove the formatting, split by line\n",
    "\n",
    "    new_lines = [] # Used to determine what the new lines will be\n",
    "    drop_lines = [] # Used to determine which lines to remove from the set\n",
    "\n",
    "    # Recreate the phoneme-word list object separating by the comma from the CSV file\n",
    "    for line in lines:\n",
    "        split_lines = line.split(\",\")\n",
    "        if len(split_lines) == 2: # Only add the line to new_lines if they are the correct size\n",
    "            new_lines.append(split_lines)\n",
    "\n",
    "        else:\n",
    "            drop_lines.append(line) # Remove the line otherwise\n",
    "\n",
    "    # Remove each element in drop_lines from the original lines list for processing\n",
    "    for line in drop_lines:\n",
    "        lines.remove(line)\n",
    "        # print(\"removed: \" + line)\n",
    "\n",
    "\n",
    "    remove_lines = [] # Lines to remove from the current dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    Remove any elements with phonetics that looks suspicious.\n",
    "    These elements are not within 3 characters of length when compared to the original word.\n",
    "    Remove the term if the line is less than 60% of the original length as well, that would imply a 40% reduction\n",
    "    in length from word to phoneme and is uncommon in the english language.\n",
    "    \"\"\"\n",
    "    for new_line in new_lines:\n",
    "        if len(new_line) == 2 and \\\n",
    "                (len(new_line[0]) < (.6 * len(new_line[1])) or len(new_line[0]) > (len(new_line[1]) + 3)):\n",
    "            remove_lines.append(new_line)\n",
    "\n",
    "        # Lines to remove from the list of words.\n",
    "        elif not len(new_line) == 2:\n",
    "            remove_lines.append(new_line)\n",
    "\n",
    "        else:\n",
    "            # Try to resolve another known edge case\n",
    "            non_abc = re.match(r\"[a-zA-Z]*[^a-zA-Z\\d\\s:][a-zA-Z]*\", new_line[1])\n",
    "            # If the match did not occur, ignore this element.\n",
    "            if non_abc:\n",
    "                print(non_abc.group(0))\n",
    "                remove_lines.append(new_line)\n",
    "\n",
    "    remove_set = set() # Set of items to be removed\n",
    "    remove_lines = remove_lines[:len(remove_lines) - 1] # Removes the empty set.\n",
    "\n",
    "    not_found = codecs.open(err_filename, \"a\") # Add all not found elements to the list of error 404s.\n",
    "\n",
    "    for remove in remove_lines:\n",
    "        #For each line that was successfully added, attempt to add it to the 404s list\n",
    "        try:\n",
    "            remove_set.add(str(remove[0]) + \",\" + str(remove[1]))\n",
    "            not_found.write(str(remove[1]) + \"\\n\")\n",
    "            print(\"Removed: \" + remove[1])\n",
    "            new_fails += 1\n",
    "        except:\n",
    "            try:\n",
    "                print(remove[0])\n",
    "                remove_set.add(str(remove[0]))\n",
    "                not_found.write(str(remove[0]) + \"\\n\")\n",
    "                new_fails += 1\n",
    "            except:\n",
    "                # If this term's formatting is bad, print this did not work and add it to the list of 404s.\n",
    "                print(\"This did not work\")\n",
    "                error = codecs.open(\"weird_words.txt\", \"a\", \"utf-8-sig\")\n",
    "                error.write(str(remove))\n",
    "                error.close()\n",
    "\n",
    "    not_found.close()\n",
    "\n",
    "    # Final set is the set of words remaining to be acquired.\n",
    "    final_set = set(lines) - remove_set - set([\"\"]) - set([\"phonemes,graphemes\\n\"])\n",
    "    purged = init_length - len(final_set) # the difference between start and end lengths is the number purged.\n",
    "\n",
    "    print(\"Total_Purged:\\t\\t\" + str(purged)) #Can be used for debugging or progress verification.\n",
    "\n",
    "    # Empty the phoneme-words file, and write the headers, \"phonemes and graphemes\" to the file first\n",
    "    end_block = codecs.open(write_file, \"w\", \"utf-8-sig\")\n",
    "    end_block.write(\"phonemes,graphemes\\n\")\n",
    "\n",
    "    # Write each of the remaining words, which should have good formatting, in final_set to the phonemes-words list.\n",
    "    for line in final_set:\n",
    "        end_block.write(str(line).lower() + \"\\n\")\n",
    "    end_block.close()\n",
    "\n",
    "    # Reopen the error file, parse the terms in it, create a set.\n",
    "    error_file = codecs.open(err_filename, \"r\", \"utf-8-sig\")\n",
    "    err = set(error_file.read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "    error_file.close()\n",
    "\n",
    "    global dict_list, curr_words\n",
    "    # Get the set of the list of words fro from final set\n",
    "    curr_words = set([word.split(\",\")[1] for word in final_set])\n",
    "    # print(curr_words)\n",
    "    # updated dict fil\n",
    "    new_len = set(dict_list) - curr_words # number of words remaining\n",
    "    # print(str(len(dict_list)) + \",\" + str(len(new_len)) + \",\" + str(len(new_len - err)))\n",
    "    dict_list = list((set(dict_list) - curr_words) - err) # Update the global list of remaining words\n",
    "    return final_set # Return the set of words remaining in the phonemes-words csv\n",
    "\n",
    "times_phon_was_run = 0 # Numebr of times the phon function was run.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The main key function used to request and process size number of word-phonetics.\n",
    "This function will only be called once every time \"size\" has been reached.\n",
    "\"\"\"\n",
    "def phon(size):\n",
    "    # access the global class variables\n",
    "    global new_size\n",
    "    global times_phon_was_run\n",
    "    global words_added, total_failed, dict_list, dict_file\n",
    "\n",
    "    # Set both words added and total failed to 0\n",
    "    words_added = total_failed = 0\n",
    "    group_size = 1000 # How many webpages to scrape before updating 404s and the words_beta word list.\n",
    "    new_size = size\n",
    "\n",
    "    times_phon_was_run += 1 # Used in debugging to track number of times this function is called.\n",
    "    # print(\"Again: \" + str(times_phon_was_run)) # Used in debugging to track number of times this function is called.\n",
    "    rounds = int(size/group_size) # The number of times to acquire group_size elements to reach size\n",
    "\n",
    "    for i in range(rounds):\n",
    "        # print(\"Round: \" + str(i))\n",
    "        urls = get_urls(group_size) # get a list of group_size urls with words from words_beta\n",
    "        get_all(urls) # concurrently acquire size number of urls, downloading up to 20 urls at a time\n",
    "        remove_invalids() # remove any and all invalid elements\n",
    "\n",
    "    urls = get_urls(size - rounds * group_size) # acquire remaining urs, since there will likely be a remainder.\n",
    "    get_all(urls) # get all of the remaining urls after all group sizes have been reached.\n",
    "\n",
    "fixed_set = remove_invalids()  # Removes around 99.9% of current invalid lines before attempting to acquire new words\n",
    "phon(new_size + total_failed)  # Run the main function\n",
    "fixed_set = remove_invalids()  # Remove invalids returns all items currently in the phonetics list\n",
    "\n",
    "\n",
    "# Keep repeating the process of getting phoneme_words until all phonetics are reached.\n",
    "while len(fixed_set) < original_size:\n",
    "    phon(original_size - len(fixed_set))\n",
    "    fixed_set = remove_invalids()\n",
    "\n",
    "\n",
    "# Log the total time the function took to run.\n",
    "total_time = time.time() - start_time\n",
    "print(total_time)\n",
    "\n",
    "# Store the time in the timing document, used to optimize the functions and decrease runtime.\n",
    "time_file = codecs.open(\"conc_timing.txt\", \"a\")\n",
    "time_file.write(str(total_time) + \"\\n\")\n",
    "time_file.close()\n",
    "\n",
    "# Update the words_beta.txt and error by subtracting all words that do not work.\n",
    "a_dict = set(codecs.open(\"words_alpha.txt\", \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "b_write = codecs.open(dict_filename, \"w\", \"utf-8-sig\")\n",
    "err = set(codecs.open(err_filename, \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "err_write = codecs.open(err_filename, \"w\", \"utf-8-sig\")\n",
    "\n",
    "new_dict_set = a_dict - err  # Subtract the set of errors from the beta dictionary\n",
    "\n",
    "# Write each line back to the beta file\n",
    "for word in new_dict_set:\n",
    "    b_write.write(word + \"\\n\")\n",
    "\n",
    "# Write each error back to the error file\n",
    "for errors in err:\n",
    "    err_write.write(errors + \"\\n\")\n",
    "\n",
    "# Close out the file\n",
    "b_write.close()\n",
    "err_write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Building the model\n",
    "\n",
    "Now we will discuss building and training the model. First well do a bit of setup, importing libraries and computing vocabularies for phonemes and graphemes. A vocabulary is a set of known tokens corresponding, in our case, to phoneme or grapheme tokens. The grapheme list will just be the English alphabet, but there are many more phonemes in the International Phonetic Alphabet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', 'k', 'y', 'ʊ', 'r', 'ɑ', 'a', 'ɪ', 'z', 'æ', 't', 'ə', 'b', 'n', 'u', 'l', 'm', 'ɛ', 'd', 'e', 'ʃ', 's', 'ʌ', 'g', 'f', 'o', 'θ', 'ɒ', 'i', 'ʒ', 'p', 'ɔ', 'v', 'ː', 'h', 'ŋ', 'w', '̃', 'ɡ', 'j', 'ɜ', 'ð', 'ʰ', 'x', 'c', 'œ', 'ü', 'ɘ', 'ø', 'ĩ']\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "# for logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# compute phoneme/grapheme vocabularies\n",
    "data = pd.read_csv(\"phonemes-words.csv\")\n",
    "phonemes_col = data[\"phonemes\"]\n",
    "graphemes_col = data[\"graphemes\"]\n",
    "# vocabularies contain 0 and 1 as start and end tokens\n",
    "phonemes = ['0', '1']\n",
    "graphemes = ['0', '1']\n",
    "\n",
    "for word in phonemes_col:\n",
    "    for phoneme in word:\n",
    "        if phoneme not in phonemes:\n",
    "            phonemes.append(phoneme)\n",
    "for word in graphemes_col:\n",
    "    for grapheme in word:\n",
    "        if grapheme not in graphemes:\n",
    "            graphemes.append(grapheme)\n",
    "\n",
    "# wow, there are lot of different phonemes!\n",
    "print(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Thats a lot of phonemes. Hopefully the model can learn all of those 🙂.\n",
    "\n",
    "\n",
    "Now lets define a couple of helper functions to encode and decode phoneme/grapheme strings. Computers can't process letters themselves, so when we feed phonemes and graphemes into the model, we will 1-hot encode them. Well also define a Pytorch Dataset object to efficiently iterate through our dataset at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nemes_to_1_hot_seq(string, nemes=\"phonemes\"):\n",
    "    \"\"\"one hot encodes the word according to either\n",
    "    the phoneme or grapheme list\n",
    "        ::returns:: pytorch tensor of one hot encoded characters\n",
    "    \"\"\"\n",
    "    string = '0' + string + '1'\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    seq = []\n",
    "    for i in string:\n",
    "        vec = [0] * len(l)\n",
    "        vec[l.index(i)] = 1\n",
    "        seq.append(vec)\n",
    "\n",
    "    return torch.FloatTensor([seq])\n",
    "\n",
    "def one_hot_to_nemes(arr, nemes=\"phonemes\"):\n",
    "    \"\"\"converts a 1-hot encoding back to characters\"\"\"\n",
    "    seq = []\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    for hot in arr:\n",
    "        x = torch.argmax(hot)\n",
    "        seq.append(l[x])\n",
    "    return seq\n",
    "\n",
    "class P2GDataset(Dataset):\n",
    "    \"\"\"Pytorch dataset object for sampling the dataset\"\"\"\n",
    "    def __init__(self, phoneme_file, device):\n",
    "        df = pd.read_csv(phoneme_file)\n",
    "        self.data = df\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, g = self.data.iloc[idx]\n",
    "        # 1-hot encoding\n",
    "        return nemes_to_1_hot_seq(p, nemes = \"phonemes\").to(self.device), nemes_to_1_hot_seq(g, nemes = \"graphemes\").long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Before getting into the model itself, lets take a look at the data. Our model will read a phonetic spelling (the first column) and attempt to output the corresponding English grapheme (the second column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 78845\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phonemes</th>\n",
       "      <th>graphemes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kyʊrɑraɪz</td>\n",
       "      <td>curarize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ætəbrɪn</td>\n",
       "      <td>atebrin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>butlɪk</td>\n",
       "      <td>bootlick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mɛndeɪʃəs</td>\n",
       "      <td>mendacious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lʌgər</td>\n",
       "      <td>lugger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ludnɪs</td>\n",
       "      <td>lewdness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nɛfroʊlɪθɒtəmi</td>\n",
       "      <td>nephrolithotomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dʒaɪənt</td>\n",
       "      <td>giant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>maɪkroʊb</td>\n",
       "      <td>microbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dɑrnər</td>\n",
       "      <td>darner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pɒtsəlænɪk</td>\n",
       "      <td>pozzolanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>proʊθɔræks</td>\n",
       "      <td>prothorax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sʌbsɪdi</td>\n",
       "      <td>subsidy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ripəzɪʃən</td>\n",
       "      <td>reposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>əfloʊt</td>\n",
       "      <td>afloat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          phonemes        graphemes\n",
       "0        kyʊrɑraɪz         curarize\n",
       "1          ætəbrɪn          atebrin\n",
       "2           butlɪk         bootlick\n",
       "3        mɛndeɪʃəs       mendacious\n",
       "4            lʌgər           lugger\n",
       "5           ludnɪs         lewdness\n",
       "6   nɛfroʊlɪθɒtəmi  nephrolithotomy\n",
       "7          dʒaɪənt            giant\n",
       "8         maɪkroʊb          microbe\n",
       "9           dɑrnər           darner\n",
       "10      pɒtsəlænɪk       pozzolanic\n",
       "11      proʊθɔræks        prothorax\n",
       "12         sʌbsɪdi          subsidy\n",
       "13       ripəzɪʃən       reposition\n",
       "14          əfloʊt           afloat"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = P2GDataset(\"phonemes-words.csv\", device)\n",
    "print(\"Size of dataset: \" + str(len(dataset)))\n",
    "dataset.data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets graph word lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate # of words of different lengths\n",
    "dict = {}\n",
    "for index in range(len(dataset.data)):\n",
    "    p, g = dataset.data.iloc[index]\n",
    "    if len(g) in dict:\n",
    "        dict[len(g)] += 1\n",
    "    else:\n",
    "        dict[len(g)] = 1\n",
    "Y = []\n",
    "for ele in dict.keys():\n",
    "    Y.append(dict[ele])\n",
    "X = dict.keys()\n",
    "fig = plt.figure()\n",
    "plt.bar(X, Y, 0.4, color=\"green\")\n",
    "plt.xlabel(\"Length of Word\")\n",
    "plt.ylabel(\"# of Words\")\n",
    "plt.title(\"# of Words of Different Lengths\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the distribution of lengths of words in the dataset. It looks like a normal with a slight leftward skew. The median word length is around 8, which happens to be the sequence length that vanilla seq2seq (e.g. Cho et al) implementations experience signifigant performance degrading. We will use a more complex architecture to hopefully deal with this, and we should expect best performance on words of length 8 since our data is concentrated there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets graph letter densities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the distribution of letters (graphemes)\n",
    "dict = {}\n",
    "for index in range(len(dataset.data)):\n",
    "    p, g = dataset.data.iloc[index]\n",
    "    lowString = g.lower()\n",
    "    for char in lowString:\n",
    "        if char in dict:\n",
    "            dict[char] += 1\n",
    "        else:\n",
    "            dict[char] = 1\n",
    "Y = []\n",
    "for ele in dict.keys():\n",
    "    Y.append(dict[ele]/len(dataset.data))\n",
    "\n",
    "X = dict.keys()\n",
    "fig = plt.figure()\n",
    "plt.bar(sorted(X), Y, 0.4, color=\"green\")\n",
    "plt.xlabel(\"letter\")\n",
    "plt.ylabel(\"Average Number of Cccurrences in a Word\")\n",
    "plt.title(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows the average amount of each letter in words in the dataset. No letter occurs more than once on average, but \"g\" is quite close. We would not expect any letters to occur more than once on average considering that the average word length is 8, but there are 26 grapheme characters. The surplus of \"g\"s is surprising and the unequal distribution of letters may lead to the model overpredicting \"g\"s. \"h\" occurs frequently, but \"f\" does not, so perhaps we will see strange spellings of the \"f\" sound, such as the well known example of \"fish\" being spelled as \"ghoti\" (\"gh\" produces the f sound as in laugh, \"o\" produces the \"ih\" sound as in women, and \"ti\" produces the shh sound as in potion). 🙂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "We tested many varieties of RNNs for this project. We tried the following combinations:\n",
    "\n",
    "Single layer GRU encoder+decoder\n",
    "\n",
    "Double/Triple stacked GRU encoder+decoder\n",
    "\n",
    "Single layer LSTM encoder+decoder\n",
    "\n",
    "We also varied hidden sizes, testing 512 or 1024\n",
    "\n",
    "We settled on the following architecture (hidden size 512):\n",
    "\n",
    "Double stacked bidirectional GRU encoder -> linear layer which accepts the last forward/backward hidden layers and converts them to a vector the size of a single hidden layer -> unstacked unidirectional GRU decoder with Bahdanau attention.\n",
    "\n",
    "## Reasoning\n",
    "Why did we choose these neural network combinations, and what were their results? <br>\n",
    "We chose these neural network types because we needed RNNs perform well with sequential data. We decided we needed more complex RNNs (e.g. LSTMs, GRUs as opposed to a vanilla Elman RNN) with cell states in order to deal with the complex and potentially long input sequences. Accuracy for these models generally sat around 30% on the test set. This means that 30% of words get spelled exactly correctly, but most words are a few characters off.\n",
    "\n",
    "What was our strategy for increasing accuracy? <br>\n",
    "\n",
    "We tried using deeper models, stacking GRUs, testing LSTMs, and introducing attention. Bahdanau attention was able to boost test test performance to 50% accuracy, a big step.\n",
    "\n",
    "What else could we do to increase the accuracy? <br>\n",
    "State of the art work on G2P for English (the opposite of our task) uses transformers. This would be the next step for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# hidden layer size\n",
    "layer_size = 512\n",
    "# define model architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(len(phonemes), layer_size, 2, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        self.fc = nn.Sequential(\n",
    "            # takes final forwards and backwards hidden states\n",
    "            nn.Linear(2 * layer_size, layer_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # push vector through encoder\n",
    "        out, hidden = self.encoder(x)\n",
    "        # hidden is [4, 1, layer_size]\n",
    "        # this is because of bidirectionality * double stacked\n",
    "        # we want to grab the \"highest\" layers from the forwards and backwards directions\n",
    "        # dim 1 because hidden[3] and hidden[4] are both [1, layer_size] and we\n",
    "        # want a single batch that has 2*layer_size values\n",
    "        hc = torch.cat((hidden[2], hidden[3]), dim=1)\n",
    "        hidden_for_init = self.fc(hc)\n",
    "\n",
    "        # return context vector\n",
    "        return out, hidden_for_init\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2 from encoder state and 1 from decoder state (since not bidirectional)\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(3*layer_size, layer_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # map energy vectors to single values\n",
    "        self.attention = nn.Linear(layer_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_hiddens, decoder_hidden):\n",
    "        # encoder_hiddens is [1, L, layer_size*2] bc bidirectional\n",
    "        # decoder_hidden is [1, layer_size]\n",
    "        # 1 bc using batch first\n",
    "        num_encoder_hiddens = encoder_hiddens.shape[1]\n",
    "\n",
    "        # make it [1,1,layer_size]\n",
    "        decoder_hidden = torch.unsqueeze(decoder_hidden, 0)\n",
    "\n",
    "        # repeat along second dim to get [4, 1, layer_size]\n",
    "\n",
    "        decoder_hiddens = decoder_hidden.squeeze(0).repeat(1, num_encoder_hiddens, 1)\n",
    "\n",
    "        inputs = torch.cat((encoder_hiddens, decoder_hiddens), 2)\n",
    "\n",
    "        energy = self.energy(inputs)\n",
    "\n",
    "        attention = self.attention(energy)\n",
    "\n",
    "        # want a distribution of attention that sums to 1\n",
    "        return F.softmax(attention, dim=2)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, attention):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        # decoder GRU takes in previous output word, attention vector, current hidden state\n",
    "        self.decoder = nn.GRU(len(graphemes) + 2*layer_size, layer_size, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(layer_size*3 + len(graphemes), len(graphemes))\n",
    "        )\n",
    "\n",
    "    def forward(self, input, hidden_layer, encoder_hiddens):\n",
    "        \"\"\"\n",
    "        Since this function gets called once at a time rather than taking in\n",
    "        a sequence of vectors, we need to pass it the last output. This will be just\n",
    "        a vector of numbers that can be converted to the embedding representing that last output\n",
    "        \"\"\"\n",
    "        # [1,1,layer_size]\n",
    "        attention_vals = self.attention(encoder_hiddens, hidden_layer)\n",
    "        attention_vals = attention_vals.permute(0, 2, 1)\n",
    "\n",
    "        # encoder_hiddens [1,L,layer_size]\n",
    "        # this just multiplies each attention value against the appropriate vector\n",
    "        # and sums the weighted vectors\n",
    "        # will be [1, 1, layer_size]\n",
    "        attended = torch.bmm(attention_vals, encoder_hiddens)\n",
    "        input = torch.cat((attended, input), dim=2)\n",
    "        out, hidden = self.decoder(input, hidden_layer)\n",
    "        # out[1] to get top hidden layer\n",
    "        input_for_fc = torch.cat((input, out), dim = 2)\n",
    "\n",
    "        return self.fc(input_for_fc), hidden\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    \"\"\"The seq2seq model itself\"\"\"\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        # instantiate encoder and decoder with attention\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder(Attention())\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, in_seq, out_seq, tf_ratio=0.5):\n",
    "        \"\"\"\n",
    "        :param tf_ratio: is the teacher forcing ratio. It decides how frequently\n",
    "        the model receives its own previously predicted token as opposed to the\n",
    "        known correct token.\n",
    "        \"\"\"\n",
    "        out_len = out_seq.shape[1]\n",
    "        # storing the outputs of the sequence\n",
    "        outputs = torch.zeros(out_len, 1, len(graphemes)).to(self.device)\n",
    "\n",
    "        out_for_at, hidden = self.encoder(in_seq)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "\n",
    "        # perform an embarassing amount of data conversions\n",
    "        input = out_seq[0].unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # for each token in known out sequence (except the first)\n",
    "        for i in range(1, out_len):\n",
    "            out, hidden = self.decoder(input, hidden, out_for_at)\n",
    "            outputs[i] = out\n",
    "\n",
    "            if random.random() > tf_ratio:\n",
    "                # teacher forcing (make next input what the current output token should be)\n",
    "                input = out_seq[i].unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "            else:\n",
    "                # use previously output token\n",
    "                x = input.argmax(1)[0]\n",
    "                input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "                input[0][0][x] = 1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def pred_new(self, in_seq):\n",
    "        \"\"\"Method to predict the output sequence for a previously unseen\n",
    "        input sequence. The main difference between this function and forward\n",
    "        is that this function only stops decoding when the model produces and\n",
    "        end token\n",
    "        \"\"\"\n",
    "        encoder_out_for_at, hidden = self.encoder(in_seq)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "        outs = []\n",
    "        while True:\n",
    "            out, hidden = self.decoder(input, hidden, encoder_out_for_at)\n",
    "            outs.append(out)\n",
    "            # in case not hitting end token\n",
    "            if len(outs) > 50:\n",
    "                break\n",
    "            x = input.argmax(1)[0]\n",
    "            input = torch.zeros(1, 1, len(graphemes)).to(self.device)\n",
    "            input[0][0][x] = 1\n",
    "            if one_hot_to_nemes(out) == ['1']:\n",
    "                break\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ready to train\n",
    "\n",
    "Now that we have a beautiful architecture, we need to instantiate it as well as a loss function and an optimizer. We use cross entropy loss since the model outputs a \"class\" (one of a number of possible tokens) at each decoding step. We'll also use Adam, since more vanilla optimizers (e.g. SGD or SGD+momentum) will tend not to converge on a network this complex.\n",
    "\n",
    "We perform a ~90%-10% train test split. The following code includes a couple of functions for computing and displaying the 0-1 accuracy of the model. 0-1 accuracy counts only the words which the model gets exactly correct.\n",
    "\n",
    "Note that hyperparameters were tuned by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture  seq2seq(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): GRU(51, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (attention): Attention(\n",
      "      (energy): Sequential(\n",
      "        (0): Linear(in_features=1536, out_features=512, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "      (attention): Linear(in_features=512, out_features=1, bias=False)\n",
      "    )\n",
      "    (decoder): GRU(1052, 512, batch_first=True)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1564, out_features=28, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "train size  70000\n",
      "test size  8845\n"
     ]
    }
   ],
   "source": [
    "# initialize optimizer/loss func/hyperparams\n",
    "EPOCHS = 15\n",
    "model = seq2seq(device).to(device)\n",
    "# what a beautiful architecture\n",
    "print(\"Model architecture \", model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# train on 70000 words\n",
    "train, test = random_split(dataset, [70000, len(dataset)-70000])\n",
    "dataloader = DataLoader(dataset=train, batch_size=1)\n",
    "print(\"train size \", len(train))\n",
    "print(\"test size \", len(test))\n",
    "\n",
    "def get_0_1_accuracy(test_set, model, prints=20):\n",
    "    \"\"\"method to compute (1 - WER) accuracy AKA what % of test_set does model get\n",
    "    exactly correct.\"\"\"\n",
    "    correct = 0\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        true = \"\".join(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))[1:-1]\n",
    "        \n",
    "        pred = \"\".join(one_hot_to_nemes(prediction, \"graphemes\"))[0:-1]\n",
    "        if prints > 0:\n",
    "            print(true)\n",
    "            print(pred)\n",
    "            prints-=1\n",
    "\n",
    "        if true == pred:\n",
    "            correct+= 1\n",
    "    if correct == 0:\n",
    "        return correct\n",
    "    return correct/len(test_set)\n",
    "\n",
    "def gen_accuracy_plot (real, pred, title):\n",
    "    \"\"\"generates and displays a plot of performance on\n",
    "    different lengths of words\n",
    "    \"\"\"\n",
    "    accuracy = {}\n",
    "    dict = {}\n",
    "\n",
    "    for i in range(len(real)): # (iterate through all elements in real)\n",
    "        if real[i] == pred[i]: # If the elements match\n",
    "           if len(real[i]) in accuracy: # if the length of the element is in dictionary \"accuracy\"\n",
    "               accuracy[len(real[i])] += 1 # add 1 to the length of the element\n",
    "           else:\n",
    "               accuracy[len(real[i])] = 1 # otherwise add the length as a new element starting from 1\n",
    "        else: # if the real element does not match\n",
    "            if len(real[i]) not in accuracy: # If the length of the real element is not in accuracy\n",
    "                accuracy[len(real[i])] = 0 # add the length as a new element starting from 0\n",
    "\n",
    "        if len(real[i]) in dict:  #if the length is already in dictionary, \"dict\"\n",
    "            dict[len(real[i])] += 1 # add one \n",
    "        else:\n",
    "            dict[len(real[i])] = 1 # otherwise add a new element for that length beginning from one\n",
    "    X = dict.keys() # get all of the total elements with each length\n",
    "    Y = [] \n",
    "    for i in X: # add each total correct element as a float to the list Y and divide by the total number of elements for that length\n",
    "        Y.append(1.0*accuracy[i]/dict[i]) \n",
    "    plt.bar(X, Y, 0.4, color=\"green\")\n",
    "    plt.xlabel(\"Length\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of model parameters:  10221868\n"
     ]
    }
   ],
   "source": [
    "print(\"# of model parameters: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wow, 10 million params! This model has more trainable parameters than tonnes of potatoes France produced in 2016! (absolutely no semantic relation). This might take a while to train, so make sure to use a NVIDIA GeForce RTX 3090 Ti 🙂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Our training loop is quite simple. We use a batch size of 1, so as not to deal with padding/packing. We record a couple metrics like loss and current accuracy on the test set as the model progresses. This part will likely take a while to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"tensorboard_data\")\n",
    "# get a mini testing batch to check model accuracy on the test set\n",
    "# throughout training\n",
    "# NOTE: this is not a validation set\n",
    "mini_test, _ = random_split(test, [20, len(test)-20])\n",
    "\n",
    "# begin training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    tot_loss = 0\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        # batch size of 1\n",
    "        in_seq = in_seq.squeeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "        # perform inference\n",
    "        model_output = model(in_seq, out_seq)\n",
    "        # dont compute loss using first token of in/out sequence\n",
    "        model_output = model_output[1:]\n",
    "        model_output = model_output.squeeze(1)\n",
    "        out_seq = out_seq.squeeze(0)[1:]\n",
    "        # compute loss\n",
    "        loss = loss_func(model_output, out_seq.argmax(1).to(device))\n",
    "        # record loss\n",
    "        tot_loss+=loss.detach().item()\n",
    "        # accumulate gradients\n",
    "        loss.backward()\n",
    "        # step and clear grads\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    tot_loss/=len(train)\n",
    "    # record current accuracy on test set and average loss\n",
    "    writer.add_scalar(\"tensorboard_data/acc\", get_0_1_accuracy(mini_test, model), epoch)\n",
    "    writer.add_scalar(\"tensorboard_data/loss\", tot_loss, epoch)\n",
    "torch.save(model, \"THEMODEL50%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_49045/1968845190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_0_1_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_49045/353536115.py\u001b[0m in \u001b[0;36mget_0_1_accuracy\u001b[0;34m(test_set, model, print)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_to_nemes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graphemes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# load model onto cpu\n",
    "model = torch.load(\"THEMODEL50%\", map_location=torch.device('cpu')).to(torch.device('cpu'))\n",
    "model.device = \"cpu\"\n",
    "# turn dropout off\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Test accuracy: \" + str(get_0_1_accuracy(test, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Well that accuracy is... disappointing. It might be better than the average human (when faced with 10s of thousands of rare words), but thats still a lot of error.\n",
    "\n",
    "What is the reason for this?\n",
    "\n",
    "Even though the attention module should, in theory, allow the model to be much more performant, the English language is rife with inconsistent spelling and pronunciation rules. Additionally, some words (e.g. their, theyre, there) are pronounced the same, so the model does not have enough information to distinguish between them. One more confounding factor is that the phonemes we are using are from the International Phonetic Alphabet, so are not as specific to the English language as the Carnegie Melon pronunciation dictionary ARPAbet (an English prononciation specification). Thus, the model needs to learn more complex rules, especially considering that there are more distinct phonemes in IPA than in ARPAbet. However, our use of IPA in theory allows better spelling on non-English words.\n",
    "\n",
    "What can we do about this poor performance? We can see a couple cells up that the model is generally off by just a few grapheme characters. Hopefully you are already thinking along the lines of spellcheck 🙂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![alt text](secret_ingredient.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function similar to the 0_1_accuracy function above, but this one just returns the lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred_lists(test_set, model):\n",
    "    \"\"\"Returns a list of correct outputs and a corresponding list of model predictions\"\"\"\n",
    "    trues = []\n",
    "    preds = []\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        true = \"\".join(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))[1:-1]\n",
    "        trues.append(true)\n",
    "        pred = \"\".join(one_hot_to_nemes(prediction, \"graphemes\"))[0:-1]\n",
    "        preds.append(pred)\n",
    "\n",
    "    return trues, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import a spellcheck library and give it our known grapheme spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "dict_filename = \"words_beta.txt\"  # `Name of the file containing many words - error\n",
    "err_filename = \"404s.txt\"  # List of all of the known error words\n",
    "\n",
    "dict_file = open(dict_filename).read()\n",
    "dict_list = dict_file.split(\"\\n\")\n",
    "\n",
    "a_dict = set(codecs.open(\"words_alpha.txt\", \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "\n",
    "err = set(codecs.open(err_filename, \"r\", \"utf-8-sig\").read().replace(\"\\r\", \"\").split(\"\\n\"))\n",
    "\n",
    "new_dict_set = list(a_dict - err)  # Subtract the set of errors from the beta dictionary\n",
    "\n",
    "spellcheck = SpellChecker().correction\n",
    "\n",
    "# Only spell check incorrect strings\n",
    "def spellcheck_1(string):\n",
    "    spellchecked = string\n",
    "\n",
    "    # Check if the presented string is in the list of known words\n",
    "    if not string in a_dict:\n",
    "        # Attempt to autocorrect the word\n",
    "        spellchecked = spellcheck(\"\".join(string))\n",
    "        # print(\"new_word: \" + spellchecked)\n",
    "    return spellchecked\n",
    "\n",
    "trues, preds = get_true_pred_lists(test, model)\n",
    "\n",
    "def spellcheck_all(str_list):\n",
    "    new_list = [None] * len(str_list)\n",
    "    str_list = list(str_list)\n",
    "\n",
    "    for i in range(len(str_list)):\n",
    "        new_list[i] = spellcheck_1(str_list[i])\n",
    "\n",
    "    # print(\"original list: \" + str(new_list))\n",
    "    return new_list\n",
    "\n",
    "def get_0_1_accuracy_with_lists(trues, preds):\n",
    "    \"\"\"compute 0 1 accuracy, but using spell check\"\"\"\n",
    "    correct = 0\n",
    "    for (true, pred) in zip(trues, preds):\n",
    "        if pred== true:\n",
    "            correct+=1\n",
    "    return correct / len(trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_checked_words = spellcheck_all(preds)\n",
    "# print(get_0_1_accuracy_with_spellcheck(spell_checked_words, trues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4947427925381572\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(get_0_1_accuracy_with_lists(trues, preds))\n",
    "gen_accuracy_plot(trues, preds, \"Accuracy on Different Word Lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6056529112492934\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(get_0_1_accuracy_with_lists(trues, spell_checked_words))\n",
    "gen_accuracy_plot(trues, spell_checked_words, \"Accuracy on Different Word Lengths (With spellcheck)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! we got a +10% accuracy boost using spellcheck.\n",
    "\n",
    "We hope you enjoyed this journey through the highs and lows of data collection and model training 🙂."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Additional Resources\n",
    "If the reader would like more resources related to this topic:\n",
    "\n",
    "For learning the basics of RNNs, LSTMs, GRUs, attention (including Bahdanau), and seq2seq architectures, these resources are good:\n",
    "\n",
    "https://www.deeplearningbook.org/contents/rnn.html\n",
    "\n",
    "https://d2l.ai/chapter_recurrent-modern/seq2seq.html\n",
    "\n",
    "https://d2l.ai/chapter_attention-mechanisms/bahdanau-attention.html\n",
    "\n",
    "For more comprehensive tutorials that walk through the full deep learning process (including varied seq2seq architectures such as transformer), this is a good resource:\n",
    "\n",
    "https://github.com/bentrevett/pytorch-seq2seq\n",
    "\n",
    "These papers discuss grapheme->phoneme conversion with deep learning. This is an easier problem, but still requires complex models for high success rates:\n",
    "\n",
    "https://arxiv.org/abs/2004.06338\n",
    "\n",
    "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43264.pdf\n",
    "\n",
    "Addtionally, here is a link to Cho et al's foundational seq2seq model paper:\n",
    "\n",
    "https://arxiv.org/abs/1406.1078"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
