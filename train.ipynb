{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoneme to Grapheme Conversion with a Recurrent Generative Model \n",
    "This project will discuss..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', 's', 'ə', 'b', 't', 'ō', 'ᵊ', 'l', 'ī', 'r', 'i', 'v', 'm', 'd', 'ä', 'h', 'y', 'ü', 'a', 'ē', 'p', 'n', 'e', 'k', 'j', 'ŋ', 'g', 'z', 'u', '̇', 'c', 'ȯ', 'w', 'f', 'ā', 'ḵ', '͟']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# find phoneme vocabulary\n",
    "data = pd.read_csv(\"phonemes-words.csv\")\n",
    "phonemes_col = data[\"phonemes\"]\n",
    "phonemes = ['0', '1']\n",
    "\n",
    "for word in phonemes_col:\n",
    "    for phoneme in word:\n",
    "        if phoneme not in phonemes:\n",
    "            phonemes.append(phoneme)\n",
    "print(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# known phonemes/graphemes\n",
    "# phonemes = ['0', '1', 'ᵊ', 'ə̇', 'ȯ', 'ē', 'ī', 'ō', 'a', 'ä', 'ɑ', 'ɒ', 'æ', 'b', 'ḇ', 'β', 'c', 'č', 'ɔ', 'ɕ', 'ç', 'd', 'ḏ', 'ḍ', 'ð', 'e', 'ə', 'ɚ', 'ɛ', 'ɝ', 'f', 'g', 'ḡ', 'h', 'ʰ', 'ḥ', 'ḫ', 'ẖ', 'i', 'ɪ', 'ỉ', 'ɨ', 'j', 'ʲ', 'ǰ', 'k', 'ḳ', 'ḵ', 'l', 'ḷ', 'ɬ', 'ɫ', 'm', 'n', 'ŋ', 'ṇ', 'ɲ', 'ɴ', 'o', 'ŏ', 'ɸ', 'θ', 'p', 'p', '̅', 'þ', 'q', 'r', 'ɹ', 'ɾ', 'ʀ', 'ʁ', 'ṛ', 's', 'š', 'ś', 'ṣ', 'ʃ', 't', 'ṭ', 'ṯ', 'ʨ', 't', 'ʂ', 'u', 'ʊ', 'ŭ', 'ü', 'v', 'ʌ', 'ɣ', 'w', 'ʍ', 'x', 'χ', 'y', 'ʸ', 'ʎ', 'z', 'ẓ', 'ž', 'ʒ', 'ʔ', 'ʕ']\n",
    "\n",
    "graphemes = ['0', '1', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# one hot encodes the word: returns an array of one hot encoded characters\n",
    "def nemes_to_1_hot_seq(string, nemes=\"phonemes\"):\n",
    "    string = '0' + string + '1'\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    seq = []\n",
    "    for i in string:\n",
    "        vec = [0] * len(l)\n",
    "        vec[l.index(i)] = 1\n",
    "        seq.append(vec)\n",
    "\n",
    "    return torch.FloatTensor([seq])\n",
    "\n",
    "def one_hot_to_nemes(arr, nemes=\"phonemes\"):\n",
    "    seq = []\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\n",
    "    for hot in arr:\n",
    "        x = torch.argmax(hot)\n",
    "        seq.append(l[x])\n",
    "    return seq\n",
    "\n",
    "class P2GDataset(Dataset):\n",
    "    def __init__(self, phoneme_file):\n",
    "        self.data = pd.read_csv(phoneme_file, header=None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, g = self.data.iloc[idx]\n",
    "        return nemes_to_1_hot_seq(p, nemes = \"phonemes\"), nemes_to_1_hot_seq(g, nemes = \"graphemes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.GRU(len(phonemes), 2048, 1, batch_first=True, bidirectional=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # push vector through encoder\n",
    "        out, h_n = self.encoder(x)\n",
    "\n",
    "        # return context vector\n",
    "        return h_n\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.GRU(len(graphemes), 2048, 1, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Linear(1024, len(graphemes))\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden_layer):\n",
    "        \"\"\"\n",
    "        Since this function gets called once at a time rather than taking in\n",
    "        a sequence of vectors, we need to pass it the last output. This will be just\n",
    "        a vector of numbers that can be converted to the embedding representing that last output\n",
    "        \"\"\"\n",
    "        out, h_n = self.decoder(input, hidden_layer)\n",
    "        # print(\"H\")\n",
    "        return self.fc(h_n), h_n\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, in_seq, out_seq, tf_ratio=0.5):\n",
    "        out_len = out_seq.shape[1]\n",
    "        # storing the outputs of the sequence\n",
    "        outputs = torch.zeros(out_len, 1, len(graphemes)).to(self.device)\n",
    "\n",
    "        hidden = self.encoder(in_seq)\n",
    "\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "\n",
    "        input = out_seq[0].unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        for i in range(1, out_len):\n",
    "            out, hidden = self.decoder(input, hidden)\n",
    "            outputs[i] = out\n",
    "\n",
    "            if random.random() > tf_ratio:\n",
    "                # teacher forcing (make next input what the current output token should be)\n",
    "                input = out_seq[i].unsqueeze(0).unsqueeze(0)\n",
    "            else:\n",
    "                x = input.argmax(1)[0]\n",
    "                input = torch.zeros(1, 1, len(graphemes))\n",
    "                input[0][0][x] = 1\n",
    "                \n",
    "        return outputs\n",
    "\n",
    "    def pred_new(self, in_seq):\n",
    "        hidden = self.encoder(in_seq)\n",
    "        input = torch.zeros(1, 1, len(graphemes))\n",
    "        outs = []\n",
    "        while True:\n",
    "            out, hidden = self.decoder(input, hidden)\n",
    "            outs.append(out)\n",
    "            x = input.argmax(1)[0]\n",
    "            input = torch.zeros(1, 1, len(graphemes))\n",
    "            input[0][0][x] = 1\n",
    "            if one_hot_to_nemes(out) == ['1']:\n",
    "                break\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq2seq(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): GRU(38, 2048, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder): GRU(28, 2048, batch_first=True)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "      (1): Linear(in_features=1024, out_features=28, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"training\"\"\"\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "EPOCHS = 100\n",
    "model = seq2seq(device)\n",
    "# what a beautiful architecture\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "dataset = P2GDataset(\"phonemes-words.csv\")\n",
    "train, test = random_split(dataset, [100, len(dataset)-100])\n",
    "dataloader = DataLoader(dataset=train, batch_size=1)\n",
    "print(len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31361199353562025\n",
      "0.2947627479424242\n",
      "0.28891884230199405\n",
      "0.28846758457480887\n",
      "0.2841919987905221\n",
      "0.2820427002476864\n",
      "0.27973661241961306\n",
      "0.27774721823754855\n",
      "0.27556742068196904\n",
      "0.27369576912434374\n",
      "0.2698882217289972\n",
      "0.2657367918090742\n",
      "0.2614299436328841\n",
      "0.25877297413153727\n",
      "0.25771349986068537\n",
      "0.2515644267445705\n",
      "0.2471187451823813\n",
      "0.24269337243721134\n",
      "0.23557110313997895\n",
      "0.23228916104455463\n",
      "0.22553191883642165\n",
      "0.22044279493513655\n",
      "0.2147321556313116\n",
      "0.21003519471917972\n",
      "0.21553336392294187\n",
      "0.20569349825382233\n",
      "0.20137122016949732\n",
      "0.19121622532361843\n",
      "0.1850236322822385\n",
      "0.1921891090231108\n",
      "0.17700066315926244\n",
      "0.16564857816995412\n",
      "0.1693400224731838\n",
      "0.15731056710155528\n",
      "0.14378468212137213\n",
      "0.13909320782709744\n",
      "0.13639116774267349\n",
      "0.13519064843898915\n",
      "0.13237064572806914\n",
      "0.11292851411310009\n",
      "0.11066420305115705\n",
      "0.1063116794494057\n",
      "0.1030740932824823\n",
      "0.09960151450960424\n",
      "0.08740644219887755\n",
      "0.08295557377993541\n",
      "0.08628377006732721\n",
      "0.07260627703398627\n",
      "0.06394558680552959\n",
      "0.05939526735641803\n",
      "0.049807104471971696\n",
      "0.05906681675028789\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_8146/516810677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtot_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_losses = []\n",
    "for epoch in range(75):\n",
    "    tot_loss = 0\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        in_seq = in_seq.squeeze(0)\n",
    "        out_seq = out_seq.squeeze(0)\n",
    "        model_output = model(in_seq, out_seq)\n",
    "        model_output = model_output[1:]\n",
    "        model_output = model_output.squeeze(1)\n",
    "        out_seq = out_seq.squeeze(0)[1:]\n",
    "        loss = loss_func(model_output, out_seq)\n",
    "        tot_loss+=loss.detach().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    tot_loss/=len(dataset)\n",
    "    print(tot_loss)\n",
    "    avg_losses.append(tot_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'd', 'ō', 'd', 'e', 'k', 'ə', 'h', 'ē', 'd', 'r', 'ə', 'n', '1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 38])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = P2GDataset(\"phonemes-words.csv\")\n",
    "p, g = dataset[10]\n",
    "\n",
    "print(one_hot_to_nemes(p[0], \"phonemes\"))\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_8146/1298819398.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# print_preds(\"data.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mget_0_1_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# print(test[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# print(one_hot_to_graphemes(torch.FloatTensor([[3,2,1],[0,0,1],[0,0,1]])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_8146/1298819398.py\u001b[0m in \u001b[0;36mget_0_1_accuracy\u001b[0;34m(test_set, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcorrect\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_8146/113457238.py\u001b[0m in \u001b[0;36mpred_new\u001b[0;34m(self, in_seq)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpred_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphemes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/yj/w4y5s1bd3z55tr6692mv9g5c0000gn/T/ipykernel_8146/113457238.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# push vector through encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# return context vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/AI-Judge/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    850\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_0_1_accuracy(test_set, model):\n",
    "    correct = 0\n",
    "    print(len(test_set))\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\n",
    "    for (in_seq, out_seq) in dataloader:\n",
    "        prediction = model.pred_new(in_seq[0])\n",
    "        if prediction == out_seq:\n",
    "            correct+= 1\n",
    "    if correct == 0:\n",
    "        return correct\n",
    "    return correct/len(test_set)\n",
    "\n",
    "def print_preds(path):\n",
    "    global p\n",
    "    print(one_hot_to_nemes(p[0], \"phonemes\"))\n",
    "    s = model.pred_new(p)\n",
    "    \n",
    "    print(one_hot_to_nemes(s, \"graphemes\"))\n",
    "\n",
    "# print_preds(\"data.csv\")\n",
    "get_0_1_accuracy(test, model)\n",
    "# print(test[0])\n",
    "# print(one_hot_to_graphemes(torch.FloatTensor([[3,2,1],[0,0,1],[0,0,1]])))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ae319d47093406129daff46394699ca00a0ff25db27d36a04b5bb5e9dd8e2e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('env-01': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
