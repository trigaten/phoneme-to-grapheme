{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Phoneme to Grapheme Conversion with a Recurrent Generative Model \n",
    "This project will discuss..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import random\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import Dataset\r\n",
    "import pandas as pd\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "# find phoneme vocabulary\r\n",
    "data = pd.read_csv(\"phonemes-words.csv\")\r\n",
    "phonemes_col = data[\"phonemes\"]\r\n",
    "graphemes_col = data[\"graphemes\"]\r\n",
    "phonemes = ['0', '1']\r\n",
    "graphemes = ['0', '1']\r\n",
    "\r\n",
    "for word in phonemes_col:\r\n",
    "    for phoneme in word:\r\n",
    "        if phoneme not in phonemes:\r\n",
    "            phonemes.append(phoneme)\r\n",
    "for word in graphemes_col:\r\n",
    "    for grapheme in word:\r\n",
    "        if grapheme not in graphemes:\r\n",
    "            graphemes.append(grapheme)\r\n",
    "print(phonemes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['0', '1', 'f', 'a', 'u', '̇', 'n', 't', 'ə', 'ü', 'ē', 's', 'i', 'p', 'y', 'l', 'ā', 'b', 'm', 'g', 'o', 'v', 'e', 'r', 'h', 'z', 'c', 'k', 'ä', 'd', 'ŋ', 'w', 'j', 'ō', 'ī', 'ȯ', '͟', 'ᵊ', 'ⁿ', 'B', 'q', 'ȧ', 'ḵ', 'ᵫ', '|', ';', '̄', 'I', '—', 'U', 'S', '₋', '3', '–', 'æ', '&', '2', 'œ']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "\r\n",
    "# one hot encodes the word: returns an array of one hot encoded characters\r\n",
    "def nemes_to_1_hot_seq(string, nemes=\"phonemes\"):\r\n",
    "    string = '0' + string + '1'\r\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\r\n",
    "    seq = []\r\n",
    "    for i in string:\r\n",
    "        vec = [0] * len(l)\r\n",
    "        vec[l.index(i)] = 1\r\n",
    "        seq.append(vec)\r\n",
    "\r\n",
    "    return torch.FloatTensor([seq])\r\n",
    "\r\n",
    "def one_hot_to_nemes(arr, nemes=\"phonemes\"):\r\n",
    "    seq = []\r\n",
    "    l = phonemes if nemes == \"phonemes\" else graphemes\r\n",
    "    for hot in arr:\r\n",
    "        x = torch.argmax(hot)\r\n",
    "        seq.append(l[x])\r\n",
    "    return seq\r\n",
    "\r\n",
    "class P2GDataset(Dataset):\r\n",
    "    def __init__(self, phoneme_file, device):\r\n",
    "        df = pd.read_csv(phoneme_file)\r\n",
    "        self.data = df.drop(df[df[\"phonemes\"].map(len) > 8].index)\r\n",
    "\r\n",
    "        self.device = device\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.data)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        p, g = self.data.iloc[idx]\r\n",
    "        return nemes_to_1_hot_seq(p, nemes = \"phonemes\").to(self.device), nemes_to_1_hot_seq(g, nemes = \"graphemes\").long()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "# define model architecture\r\n",
    "class Encoder(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.encoder = nn.GRU(len(phonemes), 1024, 1, batch_first=True, bidirectional=False, dropout=0.1)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        # push vector through encoder\r\n",
    "        out, h_n = self.encoder(x)\r\n",
    "\r\n",
    "        # return context vector\r\n",
    "        return h_n\r\n",
    "\r\n",
    "class Decoder(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.decoder = nn.GRU(len(graphemes), 1024, 1, batch_first=True, bidirectional=False, dropout=0.1)\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(1024, len(graphemes))\r\n",
    "        )\r\n",
    "        \r\n",
    "\r\n",
    "    def forward(self, input, hidden_layer):\r\n",
    "        \"\"\"\r\n",
    "        Since this function gets called once at a time rather than taking in\r\n",
    "        a sequence of vectors, we need to pass it the last output. This will be just\r\n",
    "        a vector of numbers that can be converted to the embedding representing that last output\r\n",
    "        \"\"\"\r\n",
    "        out, h_n = self.decoder(input, hidden_layer)\r\n",
    "        # print(\"H\")\r\n",
    "        return self.fc(h_n), h_n\r\n",
    "\r\n",
    "class seq2seq(nn.Module):\r\n",
    "    def __init__(self, device):\r\n",
    "        super().__init__()\r\n",
    "        self.encoder = Encoder()\r\n",
    "        self.decoder = Decoder()\r\n",
    "        self.device = device\r\n",
    "    \r\n",
    "    def forward(self, in_seq, out_seq, tf_ratio=0.5):\r\n",
    "        out_len = out_seq.shape[1]\r\n",
    "        # storing the outputs of the sequence\r\n",
    "        outputs = torch.zeros(out_len, 1, len(graphemes)).to(self.device)\r\n",
    "\r\n",
    "        hidden = self.encoder(in_seq)\r\n",
    "\r\n",
    "        out_seq = out_seq.squeeze(0)\r\n",
    "\r\n",
    "        input = out_seq[0].unsqueeze(0).unsqueeze(0).float().to(device)\r\n",
    "        \r\n",
    "        for i in range(1, out_len):\r\n",
    "            out, hidden = self.decoder(input, hidden)\r\n",
    "            outputs[i] = out\r\n",
    "\r\n",
    "            if random.random() > tf_ratio:\r\n",
    "                # teacher forcing (make next input what the current output token should be)\r\n",
    "                input = out_seq[i].unsqueeze(0).unsqueeze(0).float().to(device)\r\n",
    "            else:\r\n",
    "                x = input.argmax(1)[0]\r\n",
    "                input = torch.zeros(1, 1, len(graphemes)).to(self.device)\r\n",
    "                input[0][0][x] = 1\r\n",
    "                \r\n",
    "        return outputs\r\n",
    "\r\n",
    "    def pred_new(self, in_seq):\r\n",
    "        hidden = self.encoder(in_seq)\r\n",
    "        input = torch.zeros(1, 1, len(graphemes)).to(device)\r\n",
    "        outs = []\r\n",
    "        while True:\r\n",
    "            out, hidden = self.decoder(input, hidden)\r\n",
    "            outs.append(out)\r\n",
    "            x = input.argmax(1)[0]\r\n",
    "            input = torch.zeros(1, 1, len(graphemes)).to(device)\r\n",
    "            input[0][0][x] = 1\r\n",
    "            if one_hot_to_nemes(out) == ['1']:\r\n",
    "                break\r\n",
    "        return outs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "\"\"\"training\"\"\"\r\n",
    "from torch.utils.data import random_split\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "EPOCHS = 100\r\n",
    "model = seq2seq(device).to(device)\r\n",
    "# what a beautiful architecture\r\n",
    "print(model)\r\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\r\n",
    "loss_func = nn.CrossEntropyLoss()\r\n",
    "dataset = P2GDataset(\"phonemes-words.csv\", device)\r\n",
    "train, test = random_split(dataset, [100, len(dataset)-100])\r\n",
    "dataloader = DataLoader(dataset=train, batch_size=1)\r\n",
    "print(len(train))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "seq2seq(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): GRU(58, 1024, batch_first=True, dropout=0.1)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder): GRU(41, 1024, batch_first=True, dropout=0.1)\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=41, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "avg_losses = []\r\n",
    "writer = SummaryWriter(\"tensorboard_data\")\r\n",
    "\r\n",
    "for epoch in range(20):\r\n",
    "    tot_loss = 0\r\n",
    "    for (in_seq, out_seq) in dataloader:\r\n",
    "        in_seq = in_seq.squeeze(0)\r\n",
    "        out_seq = out_seq.squeeze(0)\r\n",
    "        model_output = model(in_seq, out_seq)\r\n",
    "        model_output = model_output[1:]\r\n",
    "        model_output = model_output.squeeze(1)\r\n",
    "        out_seq = out_seq.squeeze(0)[1:]\r\n",
    "        loss = loss_func(model_output, out_seq.argmax(1).to(device))\r\n",
    "        tot_loss+=loss.detach().item()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        optimizer.zero_grad()\r\n",
    "    tot_loss/=len(dataset)\r\n",
    "    writer.add_scalar(\"tensorboard_data\", loss.detach().item(), epoch)\r\n",
    "    # print(tot_loss)\r\n",
    "    avg_losses.append(tot_loss)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "dataset = P2GDataset(\"data.csv\", \"cuda\")\r\n",
    "p, g = dataset[0]\r\n",
    "\r\n",
    "print(one_hot_to_nemes(p[0], \"phonemes\"))\r\n",
    "p.shape\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'phonemes'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\envs\\hopkins\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopkins\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopkins\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'phonemes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/859080727.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP2GDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cuda\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_to_nemes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"phonemes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/1332705843.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, phoneme_file, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphoneme_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphoneme_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"phonemes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopkins\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\hopkins\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'phonemes'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "def get_0_1_accuracy(test_set, model):\r\n",
    "    correct = 0\r\n",
    "    dataloader = DataLoader(dataset=test_set, batch_size=1)\r\n",
    "    for (in_seq, out_seq) in dataloader:\r\n",
    "        # print(out_seq.shape)\r\n",
    "        # break\r\n",
    "        prediction = model.pred_new(in_seq[0])\r\n",
    "        # print(in_seq[0].shape)\r\n",
    "        print(one_hot_to_nemes(out_seq[0][0], \"graphemes\"))\r\n",
    "        print(one_hot_to_nemes(prediction, \"graphemes\"))\r\n",
    "        \r\n",
    "        if prediction.insert(0, '0') == out_seq:\r\n",
    "            correct+= 1\r\n",
    "    if correct == 0:\r\n",
    "        return correct\r\n",
    "    return correct/len(test_set)\r\n",
    "\r\n",
    "def print_preds(path):\r\n",
    "    global p\r\n",
    "    print(one_hot_to_nemes(p[0], \"phonemes\"))\r\n",
    "    s = model.pred_new(p)\r\n",
    "    \r\n",
    "    print(one_hot_to_nemes(s, \"graphemes\"))\r\n",
    "\r\n",
    "# print_preds(\"data.csv\")\r\n",
    "print(get_0_1_accuracy(train, model))\r\n",
    "# 36 great for train set\r\n",
    "# print(test[0])\r\n",
    "# print(one_hot_to_graphemes(torch.FloatTensor([[3,2,1],[0,0,1],[0,0,1]])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['0', 'l', 'e', 'g', 'i', 'o', 'n', 'a', 'r', 'y', '1']\n",
      "['a', 'e', 'i', 'i', 'e', 'l', 'a', '1']\n",
      "['0', 'k', 'i', 'c', 'k', '1']\n",
      "['l', 'i', 'c', 'k', '1']\n",
      "['0', 'i', 'd', 'i', 'o', 'c', 'h', 'r', 'o', 'm', 'o', 's', 'o', 'm', 'e', '1']\n",
      "['i', 'r', 'i', 'g', 'r', 'o', 'a', 'd', '1']\n",
      "['0', 'c', 'h', 'a', 'n', 'n', 'e', 'l', '1']\n",
      "['c', 'a', 'n', 'i', 'n', 'e', 'l', '1']\n",
      "['0', 'e', 's', 'c', 'h', 'e', 'a', 't', '1']\n",
      "['e', 'o', 'c', 'h', 'e', 'a', 't', '1']\n",
      "['0', 'd', 'i', 's', 'm', 'i', 's', 's', '1']\n",
      "['m', 'i', 's', 's', 'i', 's', 's', '1']\n",
      "['0', 's', 'n', 'o', 'w', 'm', 'e', 'l', 't', '1']\n",
      "['s', 'o', 'i', 'i', 'l', 'i', 'l', '1']\n",
      "['0', 'd', 'o', 'g', 'g', 'o', 'n', 'e', '1']\n",
      "['d', 'o', 'g', 'm', 'o', 'g', 'e', '1']\n",
      "['0', 'v', 'i', 'e', 't', 'm', 'i', 'n', 'h', '1']\n",
      "['v', 'i', 't', 'i', 'c', 'i', 's', 'h', '1']\n",
      "['0', 'c', 'i', 't', 'i', 'f', 'i', 'e', 'd', '1']\n",
      "['c', 'i', 't', 'i', 'c', 'i', 'n', '1']\n",
      "['0', 'a', 'r', 'a', 'd', 'i', 'd', 'a', 'e', '1']\n",
      "['a', 'o', 'r', 'k', 'i', 'i', 'l', '1']\n",
      "['0', 't', 'i', 'c', 't', 'a', 'c', 't', 'o', 'e', '1']\n",
      "['v', 'i', 't', 'i', 'c', 'c', 'a', 't', 'e', '1']\n",
      "['0', 'b', 'u', 'n', 'c', 'o', '1']\n",
      "['b', 'e', 'n', 'm', 'e', 'r', '1']\n",
      "['0', 'c', 'h', 'l', 'o', 'r', 'i', 'o', 'n', '1']\n",
      "['c', 'a', 'c', 'i', 'c', 'e', 'l', '1']\n",
      "['0', 'c', 'r', 'è', 'm', 'e', 'r', 'i', 'e', '1']\n",
      "['c', 'h', 'è', 'c', 'e', 'r', 'a', 't', '1']\n",
      "['0', 'h', 'a', 't', 'c', 'h', 'b', 'a', 'c', 'k', '1']\n",
      "['c', 'h', 'c', 'n', 'n', 'e', 'l', '1']\n",
      "['0', 'b', 'l', 'a', 'z', 'e', 'r', '1']\n",
      "['b', 'e', 'a', 'e', 'e', 'r', '1']\n",
      "['0', 'c', 'u', 't', 't', 'l', 'e', '1']\n",
      "['c', 'a', 't', 'i', 'e', 'e', '1']\n",
      "['0', 's', 't', 'a', 'u', 'n', 'c', 'h', '1']\n",
      "['s', 'o', 'i', 'u', 'l', 'i', 't', '1']\n",
      "['0', 'h', 'e', 'i', 'r', 'l', 'o', 'o', 'm', '1']\n",
      "['h', 'h', 'r', 'n', 'l', 'e', 'o', '1']\n",
      "['0', 'd', 'a', 'r', 'j', 'e', 'e', 'l', 'i', 'n', 'g', '1']\n",
      "['c', 'a', 'r', 'a', 'r', 'r', 'a', 't', 'e', '1']\n",
      "['0', 'b', 'u', 't', 'y', 'r', 'i', 'c', '1']\n",
      "['b', 'i', 'n', 'b', 'e', 'r', '1']\n",
      "['0', 'c', 'o', 'c', 'a', 'i', 'n', 'i', 'z', 'e', '1']\n",
      "['c', 'a', 'c', 'i', 'c', 'a', 'a', '1']\n",
      "['0', 'o', 'a', 'k', '1']\n",
      "['o', 'a', 'k', '1']\n",
      "['0', 's', 'o', 'u', 'r', 'd', 'i', 'n', 'e', '1']\n",
      "['s', 'o', 'p', 'p', 'u', 'i', 'n', '1']\n",
      "['0', 'r', 'i', 's', 'i', 'b', 'l', 'e', 's', '1']\n",
      "['r', 'i', 's', 'i', 'b', 'l', 'a', '1']\n",
      "['0', 'i', 'n', 'l', 'a', 'y', '1']\n",
      "['i', 'i', 'l', 'o', 'y', '1']\n",
      "['0', 'b', 'a', 'b', 'k', 'a', '1']\n",
      "['b', 'a', 'b', 'k', 'e', '1']\n",
      "['0', 'p', 'a', 'r', 'a', 'p', 'r', 'o', 't', 'e', 'i', 'n', '1']\n",
      "['p', 'a', 't', 'a', 'l', 'l', 'o', 't', 'e', '1']\n",
      "['0', 'p', 'u', 'm', 'p', '1']\n",
      "['p', 'u', 'm', 'p', '1']\n",
      "['0', 'c', 'o', 'd', 'i', 'c', 'a', 'l', '1']\n",
      "['c', 'a', 'n', 'i', 'a', 'e', '1']\n",
      "['0', 'b', 'i', 's', 'h', 'o', 'p', 'l', 'e', 's', 's', '1']\n",
      "['b', 'o', 'i', 'm', 'e', '1']\n",
      "['0', 'e', 'y', 'e', 'g', 'r', 'o', 'u', 'n', 'd', '1']\n",
      "['i', 'y', 'i', 'g', 'r', 'o', 'a', 'd', '1']\n",
      "['0', 'a', 'm', 'y', 'g', 'd', 'a', 'l', 'a', '1']\n",
      "['a', 'm', 'n', 'n', 'a', 'l', 'a', '1']\n",
      "['0', 'l', 'i', 'm', 'o', '1']\n",
      "['l', 'i', 'm', 'o', '1']\n",
      "['0', 's', 't', 'i', 'o', 'n', '1']\n",
      "['s', 't', 'i', 'm', 'n', '1']\n",
      "['0', 'r', 'e', 'i', 'v', 'e', '1']\n",
      "['r', 'r', 'a', 'c', 'k', '1']\n",
      "['0', 'f', 'i', 'b', 'b', 'e', 'r', 'y', '1']\n",
      "['b', 'e', 'b', 'k', 'e', '1']\n",
      "['0', 'i', 't', 'i', 'n', 'e', 'r', 'a', 't', 'e', '1']\n",
      "['i', 'i', 'i', 'i', 'b', 'l', 'a', '1']\n",
      "['0', 'w', 'h', 'i', 't', 'e', 'h', 'e', 'a', 'd', '1']\n",
      "['c', 'e', 'l', 'e', 'e', 'h', 'a', 'p', 'd', '1']\n",
      "['0', 'b', 'o', 'w', 'e', 'r', '1']\n",
      "['b', 'o', 'w', 'e', 'r', '1']\n",
      "['0', 'c', 'a', 't', 'e', 'c', 'h', 'i', 'z', 'e', '1']\n",
      "['c', 'a', 'n', 'i', 'e', 'e', '1']\n",
      "['0', 'b', 'u', 'r', 'b', 'e', 'r', 'r', 'y', '1']\n",
      "['b', 'u', 'r', 'b', 'e', 'r', '1']\n",
      "['0', 's', 't', 'r', 'u', 't', '1']\n",
      "['s', 't', 'r', 'u', 'o', '1']\n",
      "['0', 'm', 'o', 'u', 's', 'y', '1']\n",
      "['p', 'u', 's', 's', 'y', '1']\n",
      "['0', 'm', 'o', 'n', 'a', 'c', 'h', 'a', 'l', '1']\n",
      "['m', 'o', 'm', 'e', 'e', 'e', '1']\n",
      "['0', 's', 'o', 'l', 'e', 'm', 'n', 'i', 'z', 'e', '1']\n",
      "['s', 'e', 'l', 'e', 'm', 'n', 'l', '1']\n",
      "['0', 'r', 'i', 't', 'z', 'i', 'l', 'y', '1']\n",
      "['s', 't', 'i', 'u', 'a', '1']\n",
      "['0', 'p', 'a', 't', 'a', 'r', 'i', 'a', '1']\n",
      "['p', 'a', 't', 'a', 'r', 'i', 'a', '1']\n",
      "['0', 's', 'e', 'n', 'e', 'g', 'a', 'l', '1']\n",
      "['s', 'e', 'i', 'e', 'g', 'n', 'l', 'z', 'e', '1']\n",
      "['0', 'w', 'o', 'u', 'n', 'd', '1']\n",
      "['w', 'r', 'i', 'n', 'k', '1']\n",
      "['0', 's', 'u', 'p', 'p', 'l', 'a', 'n', 't', '1']\n",
      "['s', 'p', 'p', 'p', 'l', 'i', 'l', '1']\n",
      "['0', 'r', 'u', 'b', 'd', 'o', 'w', 'n', '1']\n",
      "['r', 'i', 'b', 'd', 'i', 's', 's', '1']\n",
      "['0', 'c', 'o', 'i', 'g', 'n', '1']\n",
      "['c', 'o', 'i', 'n', 'e', '1']\n",
      "['0', 'c', 'a', 'm', 'e', 'l', 'e', 'e', 'r', '1']\n",
      "['c', 'a', 'n', 'c', 'e', 'r', '1']\n",
      "['0', 'b', 'a', 'r', 'b', 'i', 'c', 'e', 'l', '1']\n",
      "['b', 'u', 'a', 'b', 'e', 'r', '1']\n",
      "['0', 't', 'h', 'e', 'm', 'a', '1']\n",
      "['p', 'o', 'i', 'g', 'a', '1']\n",
      "['0', 'm', 'a', 's', 'e', 'r', '1']\n",
      "['b', 'a', 's', 'e', 'r', '1']\n",
      "['0', 'p', 'a', 'i', 'l', 'l', 'e', 't', 't', 'e', '1']\n",
      "['p', 'a', 'l', 'i', 'l', 'e', 'o', '1']\n",
      "['0', 'p', 'o', 'l', 'y', 'e', 'n', 'e', '1']\n",
      "['c', 'o', 'i', 'l', 'a', '1']\n",
      "['0', 'm', 'o', 'i', 's', 't', 'e', 'n', '1']\n",
      "['m', 'o', 'm', 'e', 'u', 's', '1']\n",
      "['0', 'a', 'm', 'e', 'n', 'a', 'b', 'l', 'e', '1']\n",
      "['a', 'm', 'n', 'n', 'a', 'l', 'l', '1']\n",
      "['0', 's', 'a', 'g', 'e', '1']\n",
      "['s', 'a', 'g', '1']\n",
      "['0', 'c', 'a', 'n', 't', 'a', 'l', 'a', '1']\n",
      "['c', 'a', 'n', 'c', 'e', 'r', '1']\n",
      "['0', 'f', 'o', 'r', 'k', 'l', 'i', 'f', 't', '1']\n",
      "['b', 'u', 'b', 'k', 'e', 'r', '1']\n",
      "['0', 'f', 'a', 't', 'a', 'l', 'i', 't', 'y', '1']\n",
      "['f', 'r', 'r', 'b', 'e', 'r', '1']\n",
      "['0', 's', 'l', 'i', 'n', 'k', '1']\n",
      "['s', 'l', 'i', 'n', 'k', '1']\n",
      "['0', 'm', 'i', 's', 's', 'i', 's', 'h', '1']\n",
      "['m', 'i', 's', 's', 'i', 's', 'h', '1']\n",
      "['0', 'b', 'r', 'o', 'o', '1']\n",
      "['r', 'r', 'o', 'o', '1']\n",
      "['0', 'a', 'd', 'r', 'i', 'a', 'n', '1']\n",
      "['b', 'a', 'a', 'b', 'e', 'r', '1']\n",
      "['0', 't', 'r', 'o', 'c', 'h', 'o', 'p', 'h', 'o', 'r', 'e', '1']\n",
      "['t', 'r', 'o', 'g', 'h', 'r', 'a', 'p', 'e', '1']\n",
      "['0', 'r', 'o', 'd', 'd', 'e', 'r', '1']\n",
      "['r', 'r', 'd', 'k', 'e', '1']\n",
      "['0', 'o', 'u', 't', 'm', 'o', 'd', 'e', '1']\n",
      "['s', 'u', 't', 'm', 'o', 'd', 'e', '1']\n",
      "['0', 's', 'e', 'r', 'i', 'o', 'u', 's', 'l', 'y', '1']\n",
      "['s', 'e', 'l', 'e', 'e', 'r', 'l', 'p', 'e', '1']\n",
      "['0', 'r', 'o', 'q', 'u', 'e', 't', '1']\n",
      "['r', 'r', 'q', 'v', 'e', '1']\n",
      "['0', 'l', 'o', 't', 's', '1']\n",
      "['b', 'a', 't', '1']\n",
      "['0', 'c', 'a', 'n', 'c', 'e', 'r', '1']\n",
      "['c', 'a', 'n', 'c', 'e', 'r', '1']\n",
      "['0', 'd', 'e', 'e', 'm', 's', 't', 'e', 'r', '1']\n",
      "['d', 'e', 'e', 'm', 'e', 't', 'e', '1']\n",
      "['0', 'l', 'e', 'c', 'i', 'd', 'e', 'a', '1']\n",
      "['c', 'a', 'n', 'i', 'a', 'e', 'a', '1']\n",
      "['0', 'b', 'e', 'n', 'o', 't', 'e', '1']\n",
      "['b', 'e', 'n', 'o', 'e', '1']\n",
      "['0', 'i', 'n', 'd', 'i', 'c', 'a', 'n', 't', '1']\n",
      "['i', 'n', 'n', 'i', 'c', 'a', 'a', '1']\n",
      "['0', 'h', 'i', 'c', 'k', 'e', 'y', '1']\n",
      "['l', 'i', 'n', 'k', 'e', '1']\n",
      "['0', 'b', 'e', 'a', 'm', 'e', 'r', '1']\n",
      "['b', 'e', 'a', 'm', 'e', 'r', '1']\n",
      "['0', 'w', 'r', 'e', 'c', 'k', '1']\n",
      "['r', 'r', 'e', 'c', 'k', '1']\n",
      "['0', 'r', 'e', 'd', 'f', 'i', 's', 'h', '1']\n",
      "['r', 'u', 'd', 'f', 'i', 's', 'h', '1']\n",
      "['0', 'q', 'u', 'a', 'y', '1']\n",
      "['b', 'o', 'a', 'y', '1']\n",
      "['0', 'i', 'r', 'i', 'd', 'i', 'a', 'l', '1']\n",
      "['i', 'i', 'i', 'd', 'i', 'a', 'l', '1']\n",
      "['0', 'p', 'u', 's', 's', 'y', '1']\n",
      "['p', 'u', 's', 's', 'y', '1']\n",
      "['0', 'd', 'o', 'g', 'l', 'e', 'g', '1']\n",
      "['d', 'o', 'g', 'm', 'o', '1']\n",
      "['0', 'd', 'i', 'm', 'i', 'n', 'i', 's', 'h', '1']\n",
      "['v', 'i', 't', 'i', 'c', 'i', 's', 'h', '1']\n",
      "['0', 'i', 'm', 'm', 'e', 's', 'h', '1']\n",
      "['i', 'm', 'm', 'e', 't', 'e', '1']\n",
      "['0', 's', 'p', 'i', 'n', 'u', 'l', 'e', '1']\n",
      "['s', 'o', 'i', 'n', 'u', 'i', 'l', '1']\n",
      "['0', 't', 'r', 'a', 'u', 'm', 'a', '1']\n",
      "['t', 'r', 'a', 'u', 'm', 'a', '1']\n",
      "['0', 't', 'e', 'l', 'e', 'g', 'r', 'a', 'p', 'h', '1']\n",
      "['t', 'e', 'l', 'e', 'e', 'h', 'a', 'p', 'd', '1']\n",
      "['0', 'v', 'i', 't', 'a', 's', 'c', 'o', 'p', 'e', '1']\n",
      "['v', 'i', 't', 'i', 'c', 'c', 'a', 't', 'e', '1']\n",
      "['0', 'n', 'o', 'm', 'e', 'u', 's', '1']\n",
      "['n', 'o', 'm', 'e', 'u', 's', '1']\n",
      "['0', 'f', 'r', 'a', 'n', 'k', '1']\n",
      "['f', 'r', 'a', 'n', 'k', '1']\n",
      "['0', 't', 'r', 'o', 'u', 'n', 'c', 'e', '1']\n",
      "['t', 'r', 'o', 'u', 'n', 'e', 'e', '1']\n",
      "['0', 'a', 'd', 'o', 'n', 'i', 't', 'o', 'l', '1']\n",
      "['a', 'd', 'n', 'i', 'a', 'l', 'a', '1']\n",
      "['0', 'n', 'a', 'z', 'i', '1']\n",
      "['n', 'a', 'z', 'i', '1']\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "model.encoder.encoder.weight_ih_l0"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0039,  0.1068,  0.0548,  ...,  0.0142, -0.0038, -0.0277],\n",
       "        [-0.0430,  0.0747,  0.0009,  ...,  0.0160,  0.0036,  0.0260],\n",
       "        [-0.0219,  0.0604, -0.0052,  ..., -0.0307,  0.0280,  0.0013],\n",
       "        ...,\n",
       "        [-0.0097,  0.0188,  0.0462,  ...,  0.0221, -0.0120,  0.0051],\n",
       "        [ 0.0131,  0.0074,  0.0188,  ...,  0.0239,  0.0245, -0.0284],\n",
       "        [-0.0040,  0.0412,  0.0591,  ...,  0.0262, -0.0278, -0.0228]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05f5329ab551aa195bf58f4685173242194991f035ebb328829159f449b9089a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('hopkins': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}